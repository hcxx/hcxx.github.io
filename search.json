[{"title":"redisson使用","date":"2023-07-23T07:35:12.000Z","url":"/2023/07/23/redisson%E4%BD%BF%E7%94%A8/","tags":[["中间件","/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"本笔记基于redisson依赖，springBoot项目环境建议使用redisson-spring-boot-starter依赖。redisson锁实现同juc包中的锁。 引入依赖 真实项目中推荐redisson-spring-boot-starter。我这里使用纯redisson依赖。 配置redisson 新建MyRedissonConfig文件，此文件从nacos中的配置获取redis地址 redis的地址是配置在nacos中动态获取的。见上面配置类注释。 redisson使用 redisson是根据锁的名字来区分是否同一把锁的。 通过lock.lock(10, TimeUnit.SECONDS)方法上锁，此方法可以传参过期时间，表示时间到了之后会自动释放锁，（或者手动释放锁）。即使任务没有执行完毕，锁依旧会被释放。后续在尝试手动释放锁的时候会报锁不存在错误。 若不传时间参数lock.lock()。则锁的过期时间为30s。并且redisson的看门狗会在经过10s后自动给锁续期为30s。直到主动释放锁。假设出现硬件故障（如断电）导致程序问题主动锁释放锁失败，此时由于程序问题，看门狗不会再续期，因此时间到之后，redis中的锁会自动过期。保证了不会由于硬件问题导致的死锁。 redisson读写锁 读写锁用于读多写少的并发情况。（读多写少的数据如果不要求强一致性，只要求最终一致性，非常适合放入redis中。注意，此段括号内容说的是数据存入缓存。锁还是要的）。 读写锁互斥情况： 读、读：不互斥，可以并发 读、写：互斥，只要读锁没有释放，持有写锁的就得等待 写、读：互斥，只要写锁没有释放，持有读锁的就得等待 写、写：互斥，只要写锁没有释放，尝试获取写锁就得等待。 测试代码改数据加写锁、读数据加读锁。write接口往redis中写数据，read接口从redis中读数据 redisson信号量 同juc中的Semaphore，一般用于限制流量（如果需要限流可以使用专业的限流中间件，如GitHub - alibaba/Sentinel (面向云原生微服务的高可用流控防护组件)或 GitHub - Netflix/Hystrix）。初始化Semaphore有多少个资源。每次场次acquire会将资源减1，直到资源变为0， 此时其他想要acquire的会阻塞。直到有对象release信号量，信号量+1，才能被其他尝试acquire的获取。 countDownLatch闭锁 同juc的countDownLatch，调用await()方法的会阻塞，直到countDown被减为0。才会执行，一般用于使多个线程的任务全部完成后，在统一处理后续操作。 "},{"title":"最短路","date":"2023-06-11T13:45:16.000Z","url":"/2023/06/11/%E6%9C%80%E7%9F%AD%E8%B7%AF/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"],["图论","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/%E5%9B%BE%E8%AE%BA/"]],"content":"图论的最短路问题，介绍可参考百科：最短路问题_百度百科 最短路，部分算法可以解决负权边的问题。但是对于负环（环的和为负数）是无解的，假设在无穷远处有一个负环，他会不顾距离，走到负环处，然后一遍又一遍的走这个负环，直到累计到负无穷，并一直走下去，所以无解。后续如无特殊说明，所有图皆无负环。备注：特殊标明判断负环除外。 有向图，无向图、包括图定义等基础概念不是本篇讨论的问题，因此略去。 对于加权图，我们记为G=(V,E,W)，其中G表示图，V表示点集，E表示边集，W表示加权距离集。后续会用到邻接矩阵图（非本篇所讲基础内容，略），邻接表同理。 在邻接矩阵G表示的图中。对于两点u和v距离，如果u和v为同一点，我们记为G[u][u] = 0，即忽略自环，只取最小值0。若为不同点，则记为G[u][v] = x，为u到达v的最小加权距离。若两点之间无法到达，则记为G[u][v] = +∞+\\infty+∞。 floyd算法 关键词 多源、可有负边，时间：O(N^3)，空间：O(N^2) floyd算法用来求有向图、无向图且可以有负边的多源（以不同点为起点到不同点为终点）最短路。对于无向图，只需要把边拆成两条有向边即可。约定忽略图的自环，自环只会增加长度且无贡献。 题目：有n个编号从1到n点组成m条边的图，求图中的多源最短路。 考虑dp方法。dp[k][i][j] 表示考虑从0到k作为中转节点所有情况，对于dp[k][i][j] 所得到的最小值。即为分别考虑0到k为中转点，i到k到j获得的最小值。 显然有dp[0][i][j] = G[i][j]成立。即不经过任何点（编号为0的点不存在），最短距离为i于j的初始化距离。 考虑经过0到k-1作为中转节点的i和j，此时最短路为dp[k-1][i][j]。（考虑了0，即不经过节点中转的情况） 对于经过0到k节点。由于dp[k-1][i][j]表示考虑0到k-1任一节点中转的最小距离。即目前i到j的最小距离已经知道为dp[k-1][i][j]，此时考虑增加k节点中转，于是最短距离变为，原本经过k-1的最短距离 或 i到k的最短距离 加上 k 到 j 的最短距离中的最小值。 即在原有的0到k-1的i与j最小值路径上插入k节点，因为如3点开头所说我们只需要考虑经过0到k的节点。 由此可以推断出考虑0到k中转的i和j的最短路为dp[k][i][j] = min(dp[k-1][i][j], dp[k-1][i][k] + dp[k-1][k][j]) 即：若插入k节点，会使距离变小，则更新这个距离 因此递推公式为： dp[k][i][j]=min(dp[k−1][i][j],dp[k−1][i][k]+dp[k−1][k][j])dp[k][i][j] = min(dp[k-1][i][j], dp[k-1][i][k] + dp[k-1][k][j]) dp[k][i][j]=min(dp[k−1][i][j],dp[k−1][i][k]+dp[k−1][k][j]) 因此有伪代码： 其中k是转移阶段，当我们求k中转的时候，k-1与之前的所有数组值必须已经求出。 我们注意到，取k中转的时候，只与k-1数组的值相关，因此，可以考虑滚动数组优化空间。 更进一步的，我们可以直接复用u、v的数组，（证明暂缺😁，不会就是不会）。 dp[i][j]=min(dp[i][j],dp[i][k]+dp[k][j])dp[i][j] = min(dp[i][j], dp[i][k] + dp[k][j]) dp[i][j]=min(dp[i][j],dp[i][k]+dp[k][j]) 因此时间复杂度为O(N^3)，空间复杂度为O(N^2)。 完整代码： 注意：此代码是基于节点编号从1到n，如果从0到n-1，初始化图的代码不使用n+1。打印也从0开始。基于无向图。代码中，在遇到无穷大时不中转也很重要，保证了无穷大的一致：if (graphArr[i][k] != inf &amp;&amp; graphArr[k][j] != inf) 记录路径核心代码：基于有向图，原因见图初始化注释。代码中保证了无穷大一致，后面才可以直接用inf判断无穷大。 一组测试用例，包含负数边，所以是有向图。 第一行包含两个数n、m。n表示有编号从1到n的n个节点，m表示接下来m行。 接下来m行，每行三个整数 u，v，w，代表 u到v（单向）存在一条边权为w的边。 Bellman-Ford算法 关键词 单源、可有负边，可判断负环，时间：O(mn)，空间：O(N)。 BF算法基于松弛操作。 松弛操作：对于起点S的图，存在边(u,v)，dis(v) = min(dis(v), dis(u) + w(u, v))。即如果经过u能够使起点到v的距离变小，则更新为这个小的距离。其中dis(v)表示当前起点到v的最小距离。 BF算法的思想主要是对所有边进行松弛操作，直到松弛操作无变化为止，此时说明已找起点s到其他点最短路。最多需要对每条边松弛n-1次（即任意点k被其他n-1个点都松弛一次）操作即可。如果第n次松弛操作仍然值有改变，则说明有负环。 一点优化：在不需要判断是否有负环的情况下，for (int i = 1; i &lt; n; i++) 第一个for循环改为while循环，同时判断是否有松弛，若无松弛，则此刻已经找到最短路，停止后续遍历。 SPFA算法 关于SPFA，他死了😂。（玩笑）。SPFA，即队列优化版Bellman-Ford算法，拥有BF算法的一切特性。其平均时间复杂度为O(km)，k为每个节点平均入队次数。k大概为4左右。但是其最坏时间复杂度为O(mn)，目前对于堆优化版Dijkstra能过得题基本上都会卡SPFA。 所以，对于单源最短路，若无负权边，用堆优化版Dijkstra。若有负权边，且没有特殊性质，若SPFA能过，则BF算法一定能过（主要是BF比SPFA好写。当然平均SPFA比BF还是快的）。 对于多源最短路。若有负权变，如果数据范围允许，考虑floyd，若不允许，则应当考虑后面的johnson算法。若无负权边，跑n遍单源最短路，或者直接多源最短路，选出一个能过时间复杂度的数据即可。"},{"date":"2023-06-03T15:53:14.000Z","url":"/2023/06/03/20230603/","categories":[["undefined",""]],"content":"时间好快，这个域名使用就快要3年了。还是top便宜呀，点名批评one域名，中途涨价，翻了一倍价格。原本能买两年的钱，现在只能买一年了😭。 感觉都要续费不起one域名了。。。 其实我也挺想知道这里统计的30天内的访问人次除了我还有真人吗？不会全是爬虫吧🤣。好像各个搜索引擎也没收录吧，居然还天天爬😥。 "},{"title":"AI For Everyone笔记","date":"2023-05-29T12:21:02.000Z","url":"/2023/05/29/AI-For-Everyone%E7%AC%94%E8%AE%B0/","tags":[["AI","/tags/AI/"]],"categories":[["AI","/categories/AI/"]],"content":"Andrew Ng的《AI For Everyone》视频笔记，此课程主要是AI方向扫盲。学完只能让自己对AI相关的概念不再一无所知。并不能让自己具备AI相关的技能。 第一篇 Introduction ANI：全称artificial narrow intelligence，弱人工智能，能够完成某一特定方面的任务。例如智能音箱，自动驾驶等。 AGI：artificial general intelligence，通用人工智能（强人工智能），能够完成任何人类可以完成的事情 目前我们所接触到的AI都是ANI，离AGI的发展至少还需要很多年。 Machine Learning 监督学习：完成输入到输出的映射被称为监督学习，监督学习的数据都是有确定标注（label）的。 例如输入A是一封邮件，输出B为是否为垃圾邮件（1或0），这就是用于构建垃圾邮件筛选的AI核心思想。 对于广告推荐系统，输入一些广告信息，还有一些你的信息，然后试图预测，你是否会点击广告。 还有其他诸如音频转文字、机器翻译、基于图像雷达的自动驾驶、视觉检查等。 监督学习的飞速发展： 监督学习的概念早已存在，直到最近（大概201X年左右？）才飞速发展。主要原因是互联网和计算机的兴起，信息可以被记录再计算机里，您可以拿到的数据量有了较大增长。 对于传统的人工智能，当你输入数据更多时，它的性能会好一点，当超过一定范围，性能并不会持续增长。(有点类似于最后趋近平的对数曲线）。 但是对于现代人工智能技术以及神经网络，如果你训练的是一个稍大的神经网络，那么它的性能会比传统的人工智能性能更强。如果是一个更大规模的神经网络，那么它的性能也会变得越来越好。（最后也会趋近数据于平） 如何具有更高的性能水平： 拥有大数据量，即大数据，数据越多越好。 训练一个非常大的神经网络。 人工智能中最重要的概念就是机器学习，包括监督学习，即从输入到输出的映射，数据能使它有很好的表现。 What is data 房子大小 卧室数量 价格（1000$） 523 1 115 645 1 150 708 2 210 一个数据表格，也成为数据集，比如在一个如上的表格中。 把A设定为房子大小，B设定为房子价格，多大的房子能卖多少钱，让AI系统去学习这个输入到输出的映射，也就是A到B映射。如果我们想增加额外的条件，例如房子卧室数量，这时A就是前两列数据。所以实际上，具体什么是A、B，取决于你或你的业务。 又假设，我有一定的预算，我想知道我能买多大的房子，这时A是价格，B是房子大小。 又假设，你有一组图片数据集，其中输入A代表一组不同的图像，输出B是他们的标签，某张照片是猫，某张不是猫。 PS：把猫作为一个谈论，是机器学习的惯例。 如何获取数据： 手动标注。获取一些数据后，人工手动去标注你需要的数据关键信息，例如这张图片是猫、不是猫。手动标注，是一个让你同时拥有A和B数据集的有效方法。 观察用户的行为或其他类型行为。如电商平台上，不同的物品会有不同的价格，通过纪录用户是否购买产品，就可以收集到用户名，产品的价格，购买日期，以及购买行为等数据。 例如工厂中的机器，你想要预测一台机器是否即将出现故障，那么你可以记录一个这样的数据集，机器序列号、机器的温度、机器里的压强、和机器之前是否出现过故障。可以选择机器序列号、机器的温度、机器里的压强作为输入A，机器之前是否出现过故障作为输出B。 从网站上下载或从合作伙伴那里获取。开放的互联网上有许多数据集可以免费下载，只遵守相关协议即可。 数据是重要的，但也有2点误解 先获取足够的数据，再构建AI团队；一旦开始收集数据，马上把数据给AI团队，AI团队可以反馈给IT团队需要哪些数据，或者需要更细致的数据。 只要有数据，就会有结果；通常数据多确实比数据少要好，一些决策者认为大量数据给到AI团队，就一定能发掘这些数据的价值从而获得回报。并不总是如此。一个极端的例子，一家公司收购了许多其他医药公司的数据， 理论上讲这些数据是非常有价值的。 但是几年后， 他们的工程师们还是没有了弄明白如何使用这些数据，并且真正地从中创造价值。 不要为了获取数据而过度投资，除非同时聘用一个AI团队来研究这些数据，因为他们能分析出哪些数据是有价值的。 数据是散乱的；如果数据的质量差，那么AI会学习出不准确的结果，AI团队要解决如何清理数据的问题。处理不正确的标签。 数据的类型有很多， 图片、视频和文本这些类型的数据，称之为非结构化数据，非结构化数据没有预定义的数据模型。结构化数据是高度组织和整齐格式化的数据，容易储存在一个巨大的电子表格里。处理非结构化数据的技术要比处理这些结构化数据的技术难一点。 The terminology of AI 机器学习系统的学习从输入A到输出B的映射，从而得到一个可以运行的AI系统。 数据科学：数据科学的项目结论通常是一些帮助你做上商业决定的见解，比如建造那种房屋或者是投资翻新房子。 机器学习：机器学习是一个让电脑在不被编程的情况下，就可以自己学习的研究领域，无需显示编程， 这是Arthur Samuel几十年前提出的定义。 机器学习项目通常会带出一个运行的软件，用给定的A得到输出的B。与机器学习相比，数据科学通过挖掘数据来获取见解。通常的数据科学项目的结果是一组幻灯片。 如今大型商业网站中大多都有AI系统，例如预测你是否会点击某个广告并推送。这是一个利润丰厚的AI系统。广告行业的数据科学项目，例如数据分析得到，旅游公司没有购买足够的广告，这时可以派出更多销售人员，说服他们使用更多的广告。 即使是同一家公司，也会同时有不同的机器学习项目和数据科学项目，这两项都非常具有价值。 深度学习是一种特殊的机器学习，他通过神经网络处理输入A到输入B的映射。为了区分人的大脑，也称为人工神经网络。 人工神经网络其实是类比的人的神经网络，如下图中的小圈称为人工神经元，或简称神经元。这些神经元相互传递，神经网络其实是一个大的数据方程，根据输入A，告诉如何计算B。如今的神经网络一词几乎等同于深度学习。 你可能也在媒体上听到其他流行语如无监督学习，强化学习，图形模型，计划，知识图表等。但是机器学习、数据科学、深度学习和神经网络也是非常重要的一部分。 What makes an AI company 如何让公司擅长人工智能？从互联网的兴起中我们知道，互联网公司并不等于web网站+公司。同样，人工智能公司并不等同于使用人工智能的公司。 人工智能公司擅长数据采集。也因此大型消费科技公司会有免费产品来帮助他们收集数据，并在别处产生收益。 人工智能公司会建立统一的数据仓库。如果有非常多个不同仓库，来分别获取数据并分析，那么几乎是不可能的。 人工智能公司擅长发现自动化的机会， 人工智能公司有很多新的岗位如MLE，和新分配任务的方式。 一个公司想要变得擅长人工智能，意味着这个公司用人工智能去做某些事情，并把它做得很好。过去很多公司例如GOOGLE花费了一定时间成为擅长人工智能的公司。但这并不是一个不可复现的过程。转型人工智能公司有以下步骤： 启动试点项目，从而了解人工智能，大概知道人工智能可以做什么，不可以做什么。 在公司内部建立一个人工智能团队， 提供广泛的人工智能培训，不仅要给工程师培训，还要提供给部门领导于高层管理人员。 制定公司的人工智能发展战略。 保证内外部对于人工智能发展战略沟通一致。所有的相关人员包括顾客到投资人都知道你的公司是如何在人工智能的兴起中找到前行方向的。 What machine learning can and cannot do 本章的一点个人看法 本章中吴恩达老师介绍的AI不能做事情，但现在由于openAI的ChatGPT(聊天生成预训练转换器，基于生成型预训练变换模型3(GPT3)，是一个自回归语言模型，以监督学习和强化学习方式训练，基于深度学习方式生成人类语言)的聊天程序，吴老师当时所认为无法做到任务也被做到了。由于有一定的时间差，因此本章需要辩证看待。 通常，在开始一个人工智能项目之前，要做足够的技术调研，确保技术上是可行的。这意味着要看数据，看输入A能否完成到输出B的映射。 对于AI能做什么与不能做什么，有一个不完美的经验法则：人能够用一瞬间完成的事情，大部分都可以用监督学习来完成。例如判断周围车的距离，手机上的划痕，这些人通常耗时较短。 对于AI不能做的事情，例如让AI写一份59页的市场分析报告，因为人类还不能一瞬间写完报告。 例如，对于邮件而言，AI能对邮件进行分类，也能判断邮件是否为一封垃圾邮件。但是想让AI针对某一封邮件写出具体的内容与回信，是’目前’AI所不能做到的。AI只能生成简单的回应，例如”感谢来信，谢谢，等“，或者AI生成的是各种错乱的内容。 判断AI项目是否可行的两个经验法则： 机器只是学习一个简单的概念，这个概念不超过几秒，就可以得出一个正确的结论。例如分别一张图片是猫还是不是猫。观察其他车辆位置确定距离等。 有大量可用的数据，来学习输入A到输入B的映射。例如输入A是用户的电子邮件，输入B是用户的邮件属于什么类型，例如退款、运输、质量等。如果你有大量的A和B的电子邮件。那么该项目会更加可行。 More examples of what machine learning can and cannot do 只有我们亲眼目睹了AI成功与失败的例子，我们才能更加明确哪些AI项目能做，哪些不能做。接下来会给出更多例子。 对于自动驾驶项目，AI可以做的非常好。能通过相机、激光或者雷达等来分析他所在的位置，或者其他车的位置。这时输入A就是前方的图片或传感器数据，输出B就是其他车的位置。如今汽车行业已经收集了足够多的数据，且有相当好的算法。 现今AI无法做到的例子，例如给出一张人的手势图片，输出这个人的手势意图。这个的难点在于人的手势很多意图，不同的人的手势姿态不尽相同，因此AI通过人的手势来学习人的意图，是一个非常复杂的概念，更别说即使是人有时候也很难判断另一个人的手势的意图。 另外，这是一个对人生命安全有着重要影响的AI。一个建筑工人的手势是想让你停车还是让你继续开车，理解正确有着极大影响。这使得AI项目更加困难。 因此当今的自动驾驶汽车，有着很多的检测车辆部分的软件功能，但很少有自动驾驶团队试图依靠AI识别人类的人体姿势来安全驾驶。 使用X射线图检测肺炎的AI，输入A是X光片，输出B为是否肺炎，这是AI可以做的事情。但AI不能从解释肺炎的教科书中学习，然后检测出肺炎。但是人类可以读教科书，然后看上一小部分图像，就能对肺炎有大致的判断。AI是无法做到这一点的。 机器学习优缺点： AI擅长学习简单概念的事物，例如人几秒钟就可以做到的事情，以及有大量数据的事情。 AI不擅长从少量数据学习复杂概念。 用AI系统从未见过的新类型数据执行任务时，往往表现不佳。例如通过X射线诊断肺炎的监督学习系统中，训练时都是使用高分辨率的胸部X射线。假如将这个系统应用于其他医院，这个医院的X射线图，用户是侧躺的，由于与之前数据的巨大差异，可能结果不再准确。 一个优秀的AI团队要学会如何改善和减少这些问题。但这并不容易。如果是人，则会适应这种数据的巨大差异。 "},{"title":"那些年玩过的游戏","date":"2023-05-18T15:28:04.000Z","url":"/2023/05/18/%E9%82%A3%E4%BA%9B%E5%B9%B4%E7%8E%A9%E8%BF%87%E7%9A%84%E6%B8%B8%E6%88%8F/","categories":[["生活","/categories/%E7%94%9F%E6%B4%BB/"]],"content":"众所周知，songbirds是一个喜欢玩游戏的人。 Steam 上的 Slay the Spire Steam 上的 Left 4 Dead 2 Steam 上的 Counter-Strike: Global Offensive Steam 上的 饥荒联机版 Steam 上的 古剑奇谭三(Gujian3) "},{"title":"jMeter使用","date":"2023-05-03T13:17:16.000Z","url":"/2023/05/03/jMeter%E4%BD%BF%E7%94%A8/","categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"]],"content":"jMeter使用 1.切换语言 2.添加线程组任务 此处需要测试的http请求，然后按要求填写域名或ip地址，端口，请求类型，参数即可 需要查看结果。添加监听器。这里的监听器主要有：查看结果树、汇总报告、聚合报告、汇总图、响应时间图。主要用前三个。后面两个用于图表展示。 3.启动 启动即可 4.可能的端口占用异常 jMeter在跑大量测试的时候，模拟并发请求都会创建一个连接占用一个端口，win给TCP/IP的链接端口为1024-5000，并且四分钟循环回收，导致短时间大量请求端口占满。 解决方案参考： Jmeter跑脚本端口占用问题整理 - 知乎 WINDOWS下JMETER端口占用问题详细解决-CSDN博客"},{"title":"SpringBoot整合ES-High-Level-Client","date":"2023-04-17T14:11:26.000Z","url":"/2023/04/17/SpringBoot%E6%95%B4%E5%90%88ES-High-Level-Client/","tags":[["中间件","/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"本笔记基于rest-high-level-client，但是在ES的7.15版本rest-high-level-client现在已经被标记为过时了。推荐使用spring-boot-starter-data-elasticsearch依赖。本篇可以仅作了解。 1.建微服务 为ES单独建立一个微服务，模板建立的时候仅选择Spring-web依赖即可，我这里的spring-boot版本选择的2.6.8与其他微服务一致。 2.引入依赖 引入common微服务依赖。 引入es依赖 指定ES版本，因为是SpringBoot项目，所以ES版本会被SpringBoot版本管理，需要手动改为与自己安装的ES版本一致。按图依次点击即可查看Spring-boot管理的版本： 3.启动报错 报错信息：Error creating bean with name ‘configurationPropertiesBeans’ 报错原因：common中的alibaba-spring-cloud-nacos-discover，alibaba-spring-cloud-nacos-config两个依赖中的内部两个依赖：spring-cloud-commons、spring-cloud-context的版本，和spring-cloud-starter的内部两个依赖版本不同。 其他依赖common的微服务没有问题，是因为又引入了loader-balance之类的，其内部也有这两个依赖，覆盖之后就没有问题了。 所以我们手动引入这两个依赖，覆盖即可。引入依赖和spring-cloud-starter内部版本一致即可。 手动覆盖版本，与spring-cloud-starter保持一致 4.完整pom 5.配置bootstrap文件 6.编写ES配置文件 建立config包。于config包下创建ElasticSearchConfig类 7. 测试 "},{"title":"elasticSearch基础","date":"2023-03-26T15:04:06.000Z","url":"/2023/03/26/elasticSearch%E5%9F%BA%E7%A1%80/","tags":[["中间件","/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"elasticSearch简单介绍，注意，此笔记基于elasticsearch7版本，8版本已经移除type概念。 Elasticsearch（简称ES）是一个基于Apache Lucene™的开源搜索引擎，无论在开源还是专有领域，Lucene 可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。注意，Lucene 只是一个库。想要发挥其强大的作用，你需使用 Java 并要将其集成到你的应用中。 Lucene 非常复杂，你需要深入的了解检索相关知识来理解它是如何工作的，就跟学习 springmvc 之前先从 servlet 开始，繁琐复杂的工作，Solor、Elasticsearch 应由而生， 其使用 Java 编写并使用 Lucene 来建立索引并实现搜索功能，但是它的目的是通过简单连贯的 RESTful API 让全文搜索变得简单并隐藏 Lucene 的复杂性。 上面的介绍摘自Elasticsearch基本概念_波斯_辣椒的博客。根据 CC 4.0 BY-SA 协议获取授权并转载。（偷个懒，毕竟介绍都差不多(❁´◡`❁)）。 注：Solor是另一个lucene封装库。 Elasticsearch: 权威指南 | Elastic。中文文档，可能已经过时。 Elasticsearch Guide | Elastic。英文文档。 1.安装elasticSearch docker命令可以参考Docker命令_各种参数简介博客 通过docker下载 下载的版本是7.6.2 配置 启动Elastic search 下面的命令需要去除注释后全部执行。注意： docker run 只在第一次运行的时候使用，（后续使用docker start），用于将镜像放到容器中。不用指定容器id或名称 docker start 重新启动已存在的镜像。用于后面重新启动镜像。需要指定容器id或名称。 查看启动日志：docker logs 容器名称或ID 如果安装配置错误，可以考虑删除容器（不是删除镜像）。 docker stop 容器ID docker rm 容器ID 重新执行docker run 设置开机启动（非必须） 开放端口：9200，9300 访问 直接访问ip+端口，此处端口为上面设置的9200。若安装失败，使用docker logs 容器id查看日志。 2.安装kibana 通过docker下载，需要与elasticsearch版本保持一致 启动kibana，并设置kibana的elasticsearch地址 开放端口：5601 访问kibana 若安装成功，则可以直接访问kibana的地址。主机ip+port。此处为5601。若安装失败，使用docker logs 容器id查看日志。 3.elasticSearch概念 基本概念： 索引（indices）-------------------Databases 数据库 类型（type）----------------------Table 数据表，在indices下，可以定义一个或多个type。（ES8已移除） 文档（Document）---------------Row 行。以JSON的形式保存 字段（Field）---------------------Columns 列 正排索引： 是以文档对象的唯一 ID 作为索引，以文档内容作为记录的结构。例如关系型数据库的ID。 docID value 1 动态规划 2 动态壁纸超好看 3 好看动态图 倒排索引 将文档内容中的单词作为索引，将包含该词的文档 docID 作为记录的结构。 先经过正排索引，给文档编号，作为为唯一标识，如上正排索引的表中docID 对字段进行分词。（因此有各种分词器） 按分词建立倒排索引表。term为词，posting list为这个词在哪些docID的value中出现过 term posting list 动态 1，2，3 规划 1 好看 2，3 壁纸 2 图 3 这些词就是term，而存储原ID的是posting list，存储了所有符合某个term的文档id。 当搜索 动态高清壁纸 的时候，ID=2的命中两次，ID=1、3分别命中1次。经过一些列算法，动态壁纸超好看 分数最高。所有命中的都可以查到，但是分数较低。 当然，这样的存储肯定会特别占用内存，搜索词term的的时候也会比较耗时，底层Lucene有自己更为复杂的实现。 PS：好吧，我就是不懂😭 4.elasticSearch接口 其接口是RestFul风格的。 查看cat支持的所有指令 GET:  返回JSON 查看节点信息（_cat是Kibana 控制台） GET：。 查看节点的健康情况 GET  查看主节点信息 GET  查看ES的索引（数据库） GET  索引一个文档 GET  查询customer索引，external类型下的ID为1 post新增与修改 可以不指定ID，如果不指定，则自动生成ID。如果指定了，则是修改，同时_version会加1，_seq_no也会加1。 POST:  调用 结果 put新增与修改 必须指定ID，若没有，则是新增，否则是修改 PUT： 调用： 结果： 乐观锁修改 _seq_no，_primary_term，可以用于乐观锁更新。if_seq_no=1&amp;if_primary_term=1。通过序列好使用乐观锁 PUT： 调用 结果 post更新，带ID，带_update 如果更新的数据没有任何变化，则不进行任何操作 POST： 调用： 结果 再次调用 删除数据 DELETE： 返回数据 批量操作，只能在kibana上 如下为批量添加两条数据 elasticsearch-test-data: es测试数据 (gitee.com) 5 ES检索接口 所有的检索都是先接索引后接_search。 查询条件位于URL GET *&amp;sort=account_number:asc 查询bank索引下，查询条件为所有数据（q=*），按account_number升序排序 返回JSON 查询条件位于json（DSL查询） 查询bank索引下的数据 GET  调用 返回： 返回JSON 全文检索（分词查询） 使用match，是分词查询，会按评分进行排序 GET  调用 返回 返回JSON 短语匹配 使用match_phrase进行短语匹配。只要文档里面包含所有分词后的短语，就会被查到，是分词后去查询的，目标文档必须包含分词后的所有词，与term的精确匹配不同 GET  调用： 返回 返回JSON 多字段匹配 使用multi_match进行多字段匹配。多个字段匹配查询条件，相当于sql的or条件。会进行分词。 GET:  调用: 返回 返回JSON bool复合查询 用于构建合并多个查询条件。 must: 必须满足的条件；作为条件，同时还会贡献得分，与filter区别 must_not：必须不满足；不会贡献得分，通filter should：应该，满足了会贡献得分。 GET： 调用： 调用JSON 返回： 返回JSON filter过滤 用来作为筛选条件，不会贡献得分。不同于must与must_not GET： 调用 返回 返回JSON term与文本精确查询 term的精确匹配，不会进行分词。非文本字段的精确查询，例如年龄、金额等数字。 若需要精确检索，使用字段.keywword。 GET： 调用： 文本的精确查询 聚合检索aggs 用于对查询后的条件进行分析与提取，类似于SQL的group by和SQL的聚合函数。 搜索address为mill，所有人的年龄分布，与平均年龄。但是不显示这些人的详情。 GET： 调用： 返回： 返回JSON 按年龄分组统计数量；按年龄、性别分组统计数量； 按年龄、性别分组统计平均工资； 按年龄的平均工资 调用JSON 返回： 返回JSON 映射Mapping 类似与创建SQL时的定义的字段数据类型（不同于type）。索引下的类型（type）在ES7版本可选，8版本移除。 映射会在创建时ES自动推断 GET  获取所有字段映射 返回 返回JSON 手动创建映射，在创建索引时可以手动创建，创建my_index索引 PUT  调用 添加映射 PUT  调用 迁移数据 不支持修改索引，建议迁移。先创建索引，再迁移 PUT  调用 6 安装分词器 这里使用IK分词器，medcl/elasticsearch-analysis-ik: The IK Analysis plugin integrates Lucene IK analyzer into elasticsearch, support customized dictionary. (github.com)。下载与ES对应的ik分词器版本即可。 然解压到之前映射的plugins目录下即可。 使用Ik分词器 GET  调用 返回 "},{"title":"优先队列（堆）","date":"2023-01-15T06:45:26.000Z","url":"/2023/01/15/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%EF%BC%88%E5%A0%86%EF%BC%89/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第六章6.1节读书笔记 优先队列又称为堆，是用来处理具有优先级的元素的数据结构。 6.1 模型 优先队列分为两种。 一种是小顶堆实现的优先队列，在堆顶是最小的元素，每次可以直接访问最小的元素。 另一种是大顶堆实现的优先队列，在堆顶是最大元素。每次可以直接访问最大的元素。 对于小顶堆而言，至少支持两种操作，insert插入，将元素按优先级插入到指定位置，deletemin删除，删除堆顶的最小元素。insert操作等价于入队，deletemin等价于出队。（由堆的优先级，可以引出堆排序）。 后续以小顶堆为例。 6.2 一些简单实现 使用有序链表来实现，表头的元素最小，则每次deleteMin的时间复杂度是O(1)，对于N个元素，则是O(N)。对于每次insert操作，由于需要遍历找到插入的位置，时间复杂度是O(N)，对于N个元素，则是O(N2)O(N^2)O(N2)。 使用二叉查找树实现，二叉查找树两种操作实现皆是O(logN)O(logN)O(logN)，对于N个元素，实现是O(NlogN)O(NlogN)O(NlogN)。不过二叉查找树的实现较为复杂，而且许多支持的操作我们并不需要。将实现二叉堆，来支持这个操作，并且时间复杂度都是O(NlogN)O(NlogN)O(NlogN)。 6.3 二叉堆 堆一般指二叉堆。堆具有结构性和堆序性。对堆的一次操作，可能会破坏这两个性质中的一个。因此对于堆一次操作，必须还原这两个性质，才算作一次操作终止。 6.3.1 结构性质 堆是一棵完全二叉树，除最底层外，每一层都被填满。容易证明一棵高为h的完全二叉树有2h到2h+1−1个节点2^h 到 2^{h+1}-1个节点2h到2h+1−1个节点。即节点个数N=2h或2h+1−1个节点，因此，高度N = 2^h 或 2^{h+1}-1个节点，因此，高度N=2h或2h+1−1个节点，因此，高度h=O(logN)h = O(logN)h=O(logN)。 堆性质：堆大多都由数组实现，而不是链表。对于数组上的任一位置i的元素，其左儿子在2i，右儿子在2i+1。它的父亲在i/2上(java的整除的性质，对于节点i，无论他是左儿子，还是右儿子，整除得到的结果都是i/2)。 由于是用数组实现，当我们遍历所有元素时，可以直接通过计算，来得知访问的下标。例如下标1的左儿子在下标2，右儿子在下标3。按顺序访问。 **本节我们图示皆以二叉树展示，但是实现仍然是数组。**实现的是小顶堆。 注意：我们的堆数组，下标为0的位置是不使用的，因为2i = 0，得到的结果和父节点是一样的位置。所以有效节点从1开始。(线段树也是如此，使用数组实现树，且0的位置不使用)。 6.3.2 堆序性 对于小顶堆，根节点应该是最小的元素。同时，对于二叉堆的任意子树，也是一个小顶堆，子树的根节点也应该是子树的最小元素。 因此，对于一个小顶堆，对于任意节点i，如果其有左右子节点，则应该满足，num[i] &lt;= num[2i]，num[i] &lt;= num[2i + 1]。 根据堆序性，最小的元素总是可以以O(1)的时间在堆的根处找到。实现为findMin。 6.3.3 堆的基本操作 插入（insert） 为了将一个元素X插入到堆中，可以先在下一个可用的位置创建一个空节点。如果X可以放入该节点而不破化堆序性，那么插入完成。否则空节点应该朝着根的方向冒一步。继续该过程，知道X能被放入空节点为止。如下图，为了插入14，先创建空节点，插入14不满足，将空节点上冒，知道将14插入正确的位置。 这种策略一般叫做上滤，新元素在堆中上滤知道找出正确的位置。使用如下代码实现。 如果要插入的元素是最小的元素，那么他将一直被推向顶端。 deleteMin（删除最小元素） 最小的元素在顶端，即下标为1处。删除最小的元素，要在根节点（下标1处）建立一个空穴。将空穴中的两个字节的的较小值移入空穴，则空穴下移动一层。重复这一过程。最后再将堆中的最大元素（如图31）被移入空穴。 代码实现 建堆 通过初始构造集合建堆，可以考虑建堆使用N个insert方法来建堆，每个insert的平均时间是O（1）,而最坏的时间是O（lgN）。因此总的平均时间为O（N），总的最坏时间为O（NlgN）。 一般的算法是将N项以任意顺序放入堆中，保持结构性，此时percolateDown(i)从节点i下滤，使用如下的程序创建一棵堆序的树。 6.4 完整代码 堆完整代码 "},{"title":"数论杂项","date":"2023-01-14T14:47:32.000Z","url":"/2023/01/14/%E6%95%B0%E8%AE%BA%E6%9D%82%E9%A1%B9/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"数论杂项 取余（区别python的取模） 注意：对于取余，下面统一用%符号，对于取模，统一用mod关键字 区别于python，java中的负(正)数 / 负(正)数 = 答案，这个答案会向0靠近，取模的结果就是剩下的数，例如： −7/4=−1余−3−7/−4=1余−37/−4=−1余3\\begin{aligned} {-7} / 4 &amp;= {-1}余{-3} \\\\ {-7} / {-4} &amp;= {1} 余 {-3} \\\\ 7 / {-4} &amp;= {-1} 余 3 \\end{aligned} −7/4−7/−47/−4​=−1余−3=1余−3=−1余3​ 取模分配律（除法例外） 除法的取模需要进行逆元运算才能求解。 (a+b) mod p=(a mod p+b mod p) mod p(a−b) mod p=(a mod p−b mod p) mod p(a∗b) mod p=(a mod p∗b mod p) mod pab mod p=((a mod p)b) mod p\\begin{aligned} (a + b)\\ mod \\ p &amp;= (a\\ mod \\ p + b\\ mod \\ p)\\ mod \\ p \\\\ (a - b)\\ mod \\ p &amp;= (a\\ mod \\ p - b\\ mod \\ p)\\ mod \\ p \\\\ (a * b)\\ mod \\ p &amp;= (a\\ mod \\ p * b\\ mod \\ p)\\ mod \\ p \\\\ a ^ b\\ mod \\ p &amp;= ((a\\ mod \\ p) ^ b)\\ mod \\ p \\end{aligned} (a+b) mod p(a−b) mod p(a∗b) mod pab mod p​=(a mod p+b mod p) mod p=(a mod p−b mod p) mod p=(a mod p∗b mod p) mod p=((a mod p)b) mod p​ 取模同余定理 对于(a−b) mod k=0(a - b) \\ mod \\ k = 0(a−b) mod k=0，则有a mod k=b mod ka \\ mod \\ k = b \\ mod \\ ka mod k=b mod k。对于python，本身就是取模，直接取模运算即可。 对于java的取余需要特殊处理一下，(a % k+k) % k=(b % k+k) % k(a \\ \\% \\ k + k)\\ \\% \\ k = (b \\ \\% \\ k + k)\\ \\% \\ k(a % k+k) % k=(b % k+k) % k 用途： 974. 和可被 K 整除的子数组 - 力扣（LeetCode），前缀和处理后，(sum[j] - sum[i]) % k = 0的换处理。 字符串Hash文章中 字符串Hash，代码里面取余(大于k，取余变小)后，再去减(小于k，不变)可能出现负数情况的处理（见代码注释）。转换为整数。"},{"title":"质数","date":"2023-01-02T05:38:46.000Z","url":"/2023/01/02/%E8%B4%A8%E6%95%B0/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"质数相关 写这个的原因，主要是第 326 场周赛 - 力扣（LeetCode），多道题目考到了质数，也是本人第一场AK的周赛。LC给大家2023年的第一场福利周赛。 1. gcd（最大公因数） 求解两个数的最大公因数，例如24、30的最大公因数是6. 1 辗转相除法 辗转相除法的公式为：gcd(a,b) = gcd(b, a mod b)。具体示例如下：假如需要求 1997 和 615 两个正整数的最大公约数,用欧几里得算法，是这样进行的： 辗转相除法步骤 1997 ÷ 615 = 3 (余 152) 615 ÷ 152 = 4(余7) 152 ÷ 7 = 21(余5) 7 ÷ 5 = 1 (余2) 5 ÷ 2 = 2 (余1) 2 ÷ 1 = 2 (余0) 1 ÷ 0 = ？ 直到b = 0，至此，最大公约数为a = 1 时间复杂度：对于gcd(a, b)，假设b &lt;= a，则gcd的时间复杂度为O(logb)。 2 使用java的API java的bigInteger有求解gcd的的API，但是必须把数字转为bigInteger。 2. 判断一个数质数 使用试除法，如果能够整除以一个数，则说明不是质数。优化点，是我们只用试除到N\\sqrt{N}N​即可，因为如果是合数（非质数），则N = a * b，（假设b &lt;= a），则有b &lt;= N\\sqrt{N}N​成立。说明我们试除到N\\sqrt{N}N​，就相当于尝试了所有可能的可以整除的数。 时间复杂度：O(N)O(\\sqrt{N})O(N​)。 3.分解质因数 分解一个数的所有质因数。采用试除法，从最小的2开始。获取所有最小能够整除以的数。然后一直除下去。 时间复杂度：O(N)，在N是质数的情况下，达到最坏的情况。 更新：O(N\\sqrt{N}N​)，同判断一个质数，即使在最坏的情况下，我们也只需要试分解到O(N\\sqrt{N}N​)。 4.获取1到n的所有质数 4.1 暴力 采用判断一个数是否是质数的方法，从2判断到n，暴力的筛选出所有质数。 时间复杂读：不清楚^_^，大概范围是O(N) &lt; t &lt; O(N^2) 4.2 埃式筛 埃式筛的代码比较简单，且复杂度也只多了loglogN，在不特别严苛的情况下使用埃式筛即可。 埃拉托斯特尼筛法，简称埃拉托斯特尼筛法_百度百科，要得到自然数n以内的全部素数，必须把不大于根号n的所有素数的倍数剔除，剩下的就是素数。 给出要筛数值的范围n，找出以内的素数。先用2去筛，即把2留下，把2的倍数剔除掉；再用下一个质数，也就是3筛，把3留下，把3的倍数剔除掉；接下去用下一个质数5筛，把5留下，把5的倍数剔除掉；不断重复下去…。 时间复杂度：O(nloglogN) 埃式筛步骤 列出2以后的所有序列： 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 标出序列中的第一个素数，也就是2，序列变成： 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 将剩下序列中，划掉2的倍数，序列变成： 2 3 5 7 9 11 13 15 17 19 21 23 25 剩下的序列中第一个素数是3，将主序列中3的倍数划掉，主序列变成： 2 3 5 7 11 13 17 19 23 25 我们得到的素数有：2，3 直到标出所有素数 2 3 5 7 11 13 17 19 23 特别注意：筛法的方法建议写成静态的，然后静态调用。否则多次初始化会被LC卡掉。 另外大多数时候我们需要的最终结果集是一个SET。此筛法的ansList，不参与取值过程，可以直接改成set。 4.3 欧拉筛（线性筛） 欧拉筛是对埃氏筛的改进，避免重筛，提高效率。但代码会更加复杂，只做介绍。 欧拉筛的核心思想就是确保每个合数只被最小质因数筛掉。或者说是被合数的最大因子筛掉。 欧拉筛步骤 比如说 1 ，2，3，4，5，6，7，8，9，10，11， 12 当 i=4时： primes = {2, 3} 此时i%2=0, 如果不结束内层循环的话,12会被3∗4筛掉， 当i=6时，12又会被2∗6筛掉。 特别注意：建议静态。同时ansList不能改成SET，在遍历ansList需要其有序，set会破坏这个有序。最后new HashSet&lt;&gt;(ansList)即可。 5.LCM（最小公倍数） 公式：最小公倍数= (a * b) / gcd(a, b ) "},{"title":"字符串Hash","date":"2022-11-27T14:59:14.000Z","url":"/2022/11/27/%E5%AD%97%E7%AC%A6%E4%B8%B2Hash/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"字符串的匹配算法之一，字符串匹配个人觉得比较复杂，所以单独写一篇 字符串查找算法中，一个很重要的算法是KMP，但是KMP的理解与记忆还是比较困难的。 而字符串Hash算法则是一种比较容易简单的算法。但是字符串Hash算法仍然有其缺陷，就是Hash冲突的存在，无论怎么处理，冲突的概率只会降低，不会完全消失。但好在，一般的题目降低到较低的冲突概率即可AC。 1.字符串Hash原理 我们要在一个主串中查找一个模式串，则模式串的长度是已知的为n。字符串Hash的本质原理是枚举所有长度为n的子串的Hash值。所以如何能够快速的求出以left为起点，right为结束点，长度为n的字符串的Hash值。是最为关键的。 字符串Hash使用进制思想求出Hash值，使用前缀和以O(1)的时间求出left到right的Hash值。 对于字符串abc，计算Hash值时，我们将其转换为一个p进制数，其Hash值计算如下(未取模)： a=a的ASCII码值∗p0ab=a的ASCII码值∗p1+b的ASCII码值∗p0abc=a的ASCII码值∗p2+b的ASCII码值∗p1+c的ASCII码值∗p0\\begin{aligned} a &amp;= a的ASCII码值 * p^0\\\\ ab &amp;= a的ASCII码值 * p^1 + b的ASCII码值 * p^0\\\\ abc &amp;= a的ASCII码值 * p^2 + b的ASCII码值 * p^1 + c的ASCII码值 * p^0\\\\ \\end{aligned} aababc​=a的ASCII码值∗p0=a的ASCII码值∗p1+b的ASCII码值∗p0=a的ASCII码值∗p2+b的ASCII码值∗p1+c的ASCII码值∗p0​ 则字符串bc的Hash快速取值如下： bc=b的ASCII码值∗p1+c的ASCII码值∗p0=abc−a∗p2\\begin{aligned} bc = b的ASCII码值 * p^1 + c的ASCII码值 * p^0 = abc - a * p^2 \\end{aligned} bc=b的ASCII码值∗p1+c的ASCII码值∗p0=abc−a∗p2​ 具体的我们可以有： Hash[left到right]=Hash[right]−Hash[left−1]∗pArr[right−left+1]Hash[left到right] = Hash[right] - Hash[left - 1] * pArr[right - left + 1] Hash[left到right]=Hash[right]−Hash[left−1]∗pArr[right−left+1] 于是我们可以开辟两个数组，一个存储到下标1到下标i的Hash值，一个是下标i的进制值幂次结果。 2.双Hash取模 单Hash取模，就是只模一次，比双模冲突的概率高一点。节省版面，只介绍双hash取模。 所谓的双Hash取模，即只取两次模。进制质数：131，13331 ； 取模质数： 1e9 + 7，1e9 + 9。 这几个数都是经验值。两种数都取质数，能显著降低冲突。 同时取模质数应该尽可能的大。同时数组要开long数组，避免溢出变为负数的情况。还要使用同余定理，避免求left到right减出负数的情况。 模板题：28. 找出字符串中第一个匹配项的下标 - 力扣（LeetCode） "},{"title":"LC周赛记录","date":"2022-11-20T05:23:18.000Z","url":"/2022/11/20/LC%E5%91%A8%E8%B5%9B%E8%AE%B0%E5%BD%95/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"记录LC周赛问题 第 320 场周赛 - 力扣（LeetCode） 6242. 二叉搜索树最近节点查询 - 力扣（LeetCode） 问题：TLE 二叉搜索树不一定平衡：题目给出了二叉搜索树，但普通的二叉搜索树不一定是平衡的，当用例的二叉搜索树退化为链表时，时间会达到线性的时间复杂度，从而被卡掉。 第 327 场周赛 - 力扣（LeetCode） 6284. 使字符串总不同字符的数目相等 - 力扣（LeetCode） 问题：读题不仔细、简单的暴力想复杂 题目是要求能否两个单词中不同的字符数目是否能够相等，是字符去重后的个数是否相等。且题目说明了恰好移动一次，没有注意到该条件，以为可以移动多次。 如果只移动一次，则应该暴力求解，尝试每一种交换的可能，最多尝试26*26次（字母只有26个，且只交换一次），时间复杂度是可以满足的。（O(N) = max(26 * 26, max(len(word1), len(word2))）。 第 340 场周赛 - 力扣（LeetCode） 2614. 对角线上的质数 - 力扣（LeetCode） 使用了埃氏筛，筛选只需要一次即可，但是筛选写在了普通方法里面，导致每一次调用都会跑一遍埃氏筛，最终导致了超时。改成静态后通过。 第 342 场周赛 - 力扣（LeetCode） 2653. 滑动子数组的美丽值 - 力扣（LeetCode） 虽然nums.length=1e5，但是nums[i]的值域只有-50到50，使用桶排序（基数排序）即可满足，快排会导致时间复杂度超时。 第 351 场周赛 - 力扣（LeetCode） 6910. 将数组划分成若干好子数组的方式 - 力扣（LeetCode） 以后若是要求取余的题目，必须边计算边取余，不能只在最后一步取余，若是加法，直接取余到底即可，若是减法（可能减出负数），则需要加上取模同余定理。即若求(-x) % mod的余数，这里-x表示负数： (−x)%mod=(−x%mod+mod)%mod(-x) \\% mod = (-x \\% mod + mod) \\% mod (−x)%mod=(−x%mod+mod)%mod 其他可能用到的，注意其中a+b、a*b为正数，否则需要使用上面的同余定理： (a+b)%m=((a%m)+(b%m))%m(a+b)\\%m=((a \\% m)+(b \\% m)) \\% m (a+b)%m=((a%m)+(b%m))%m (a∗b)%m=((a%m)∗(b%m))%m(a*b)\\%m=((a \\% m)*(b \\% m)) \\% m (a∗b)%m=((a%m)∗(b%m))%m"},{"title":"经典算法","date":"2022-09-05T01:12:06.000Z","url":"/2022/09/05/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"一些最经典（基础）的算法 1. 排序 1.快速排序 只掌握快速排序的递归写法即可 普通快速排序，在数组逆序且有序的情况，会达到最坏的情况，从而被用例卡掉。 普通快速排序 三数取中快速排序：将arr[left]、arr[mid]、arr[right]排序，取arr[eft]、arr[mid]、arr[right]的中位数，用中位数作为基准，这样就能避免最坏的情况。 三数取中快速排序 2.归并排序 归并排序 3.堆排序 递归版本 堆排序 2.二叉树 0.二叉树简易定义 1.DFS DFS的递归实现 DFS的迭代实现 迭代使用栈保存节点实现 DFS迭代 2. BFS BFS的迭代实现 BFS的递归实现（了解） 3.单调队列 单调队列，注意与单调栈做出区分。单调队列用于得到当前的某个范围内的最小值或最大值 单调栈：没有长度，当不单调时，只能从栈首弹出。都是在尾部添加。 6247. 从链表中移除节点 - 力扣（LeetCode）：单调栈参考题目 单调队列：一般有长度，除了从尾部弹出，当长度超过限制后，会从首部移除元素。都是在尾部添加。 239. 滑动窗口最大值 - 力扣（LeetCode）：单调队列模板题 4.并查集 并查集分为并与查两部分，主要用于查找一个对象是否属于一个集合，有两点优化： 路径压缩（找到节点i的祖先节点后，将i直接指向祖先节点，一般必须）。 按秩合并（节rank低的合并到rank高的上去，就是节树高度小的合并到高度大的上去，从而不增加树的高度。有点问题，暂未实现）。 模板题：剑指 Offer II 116. 省份数量 - 力扣（LeetCode） 并查集 5.拓扑排序 207. 课程表 - 力扣（LeetCode）：拓扑排序模板题目 6.线段树 单点修改线段树模板：暂记，需要整理 模板题：307. 区域和检索 - 数组可修改 "},{"title":"统一异常处理","date":"2022-07-05T15:30:17.000Z","url":"/2022/07/05/%E7%BB%9F%E4%B8%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","tags":[["spring","/tags/spring/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"Spring统一异常处理与jsr303分组验证 统一异常处理与JSR303 1. 自定义全局统一异常 在需要使用统一异常处理的微服务下创建exception包，并创建统一异常处理类。 2. 自定义异常状态 这里的异常状态是可以通用的，所以可以写入common服务中 jsr303校验 1. 高版本spring校验依赖添加 考虑到大多数服务多需要校验，可以直接添加在common服务里。这里的版本最好和srping-boot版本一致。 2. 简单校验参数 如果要对controller的入参进行校验，则需要使用注解显示的开启校验。使用@Validated，由spring提供，(另有@Valid由javax提供)。 3.分组异常校验 有时候，某个字段，例如Id，再新增的时候必须为null，在更新的时候必须是不为null，实体类上的校验注解无法直接区分，这时候就需要进行分组校验了。分组校验就是在实体类上的校验注解加上groups数组的属性，数组中的类是空标记类，用来标记分组。同时controller方法上指明是哪一个标记。表示这个方法只校验所属groups的注解。 message是出现异常的时候返回的异常信息，groups表示这个实体类被标记为哪些操作下需要校验。例如brandId字段我们同时指定Null与NotNull，在更新时必须不能为空，新增时必须为空。 业务上我们规定：AddGroup类为新增标记类，UpdateGroup为更新标记类。 注意：一旦接口开启了分组校验，则实体类所有字段必须指明分组，否则不再生效，要么不指明分组（即不分组），要么全部指明。 4. 自定义校验注解 正则表达式：可以使用正则表达式来实现自定义的目的。@Pattern 编写一个自定义的校验注解：@ListValue(value=(0,1))。该自定义注解规定只能使用values值0和1 编写时可以参考已经存在的官方注解，例如@NotNull等。该注解有三个属性message、groups、payload message：在使用者不指定message的情况下，默认返回的报错信息。 groups：支持分组校验，默认不分组 payload：使用者可以通过此属性来给约束条件指定严重级别. 这个属性并不被API自身所使用。 自定校验注解 resources下创建配置文件ValidationMessages.properties 编写自定义校验器类 要实现ConstraintValidator类，两个范形，第一个是ListValue，表示要校验的注解。第二个是Integer，是该注解只能作用于Integer字段。然后重写两个方法 使用自定义注解 "},{"date":"2022-07-04T14:19:36.000Z","url":"/2022/07/04/20220704/","categories":[["undefined",""]],"content":"感觉今年的TODO又要鸽了。。。 "},{"title":"Spring-Cloud-alibaba配置笔记","date":"2022-06-18T14:36:50.000Z","url":"/2022/06/18/Spring-Cloud-alibaba%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/","tags":[["spring","/tags/spring/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"spring-cloud-alibaba配置笔记 管理依赖 在common微服务单独添加如下依赖，该依赖会SpringCloud-alibaba的所有组件进行依赖管理。然后所有微服务必须引入common依赖， 注意：common创建是使用idea自带的maven脚手架创建，而不是springBoot，所以没有启动类 Common服务 某单独微服务的pom参考 Nacos注册中心 1. 依赖引入(只common) 2. 启用服务服务发现 添加@EnableDiscoveryClient注解，添加完后应该如下，所有微服务需要注册 3. 配置文件nacos相关(yml) 也可以后续用写入bootstrap.yml中，参考Naocs配置中心章节 4. 启动nacos Feign 申明式的远程调用http客户端（现在已经支持RPC调用了） 1. 依赖引入(所有需要使用Feign的微服务，除common) 注意：在使用idea的springBoot脚手架创建每个微服务时，我们已经选择fegin的初始化创建(同时也选择了web-starter)。所以不再需要引入依赖。 但是，在新版OpenFign使用了RPC的远程调用，需要同时加入一个新的依赖，加完后这两个依赖如下。（版本已经交给dependencyManagement管理，所以不再需要配置版本） 2. 申明feign创建调用 在Application启动类同级目录下创建feign文件夹，后面的的远程调用写在此文件夹中，方便管理。 3. 申明启用feign调用 开启feign的注解, 指定feign要扫描的指定地址下的所有接口 Nacos配置中心 1. 依赖引入（只common） 2. 配置文件 resources目录下辖创建bootstrap.properties文件，该文件会先于application.properties文件加载。必须要先于加载，加载后去配置中心读取配置文件。如下配置文件皆是修改bootstrap文件。如果只看结果，翻到最后一点即可。 读取流程： 先通过配置地址server-addr查找到nacos， 再通过命名空间，查找到uuid为‘361a2167-5594-4440-ac8e-ea927be56c67’的命名空间（如无则为public） 再查找组名。（如无则为DEFAULT_GROUP） 再查找应用名server1。找到server1.后缀的作为配置文件。 Nacos网页配置列表添加 打开左侧配置管理/配置列表，点击加号，Data ID是应用名称，就是上面一点配置文件中的spring.application.name=microServer的microServer，一般取名为微分服务的最外层文件夹名。例如：·/father/example/src/main…·，其中father为聚合服务，example为微服务应用名。 引入配置参数类加注解 引用了application.properties的文件，需要加上注解@RefreshScope，才能实时更新，动态获取配置值。 如果配置中心和配置文件都使用了相同的配置项，优先使用配置中心的配置。 3. 以开发测试生产命名空间(不太推荐) 命名空间主要是用来区分，开发、测试、生产的环境的配置文件。默认有一个public，利用命名空间做环境隔离，需要在bootstrap.properties配置上，需要使用哪一个命名空间下的配置文件。 如果微服务众多，可以每一个微服务都创建自己的命名空间。只加载自己命名空间下的所有配置。 创建完成后，配置列表会多如下的可选择项。 然后根据需要，在配置文件中指定要使用的命名空间的uuid。 4. 以每个微服务作为命名空间 配置列表中，选择克隆，可以从其他命名空间复制配置文件。 5. 配置分组 图中同一命名空间下有相同的Data_ID的。但是分组不同，可于配置文件中配置分组。 6. 通过分组隔离环境 分dev组和prod组 7. 使用配置集 yaml中的配置可以进一步的拆分，如下将原本的配置application.yml配置文件拆分成datasource、mybatis、other模块。在配置集中没有的参数，会去指定的空间与组名中尝试去查找。 Gateway网关 gateway用来做网关。使用idea的spring脚手架初始化项目， 1. 依赖引入 bootstrap.properties 添加配置 application.properties 添加配置 2. 注解配置 在启动类上添加启用Nacos注解，同时排除myabtis自动配置的。 Nacos注册 在Nacos中给gateway创建命名空间。并创建Data_ID的yaml配置文件。同时创建bootstrap.properties文件。 路由规则 gate可以创建路由规则，在满足断言的情况下，可以路由到指定的地址，创建application.yml文件，创建如下路由规则。 "},{"date":"2022-06-01T16:10:31.000Z","url":"/2022/06/02/%E9%BB%91%E6%B3%A51/","categories":[["undefined",""]],"content":" 86daf2dd9f98eea2571c3fce34d1e7adf8c6f0caba96db9f885791bfddfd9e13cc6352411bbae3995b93ccb7bfc42fd5a7184de460fdd8522a114f937646ff6c56555eb97418a0ba59fe4068db6e9d98d3e3e2904d59492f1fa291f3ee26e1a4b352e6172628f576dde9b3c87ee33a83317388418a5a89a3177f11e5d9e8e26f 您好, 这里需要密码. "},{"title":"不使用链表的散列","date":"2022-04-17T05:34:31.000Z","url":"/2022/04/17/%E4%B8%8D%E4%BD%BF%E7%94%A8%E9%93%BE%E8%A1%A8%E7%9A%84%E6%95%A3%E5%88%97/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第五章5.4节读书笔记 分离链接法的缺点是使用了散列表，给这些新单元分配地址需要时间，导致算法速度有些减慢。另一种不使用链表的解决方法是尝试另外一些单元，直到找出单元为止。常见的是单元h0(x),h1(x),h2(x),...h_0(x),h_1(x),h_2(x),...h0​(x),h1​(x),h2​(x),...相继被试选，其中hi(x)=(hash(x)+f(i))modTableSizeh_i(x) = (hash(x) + f(i)) \\quad mod \\quad TableSizehi​(x)=(hash(x)+f(i))modTableSize，且f(0) = 0。函数f是冲突解决方法。一般来说其装填因子λ=0.5\\lambda = 0.5λ=0.5。这样的表叫做探测散列表。 5.4.1 线性探测法 线性探测法中，冲突解决函数f是i的线性函数，典型的是f(i) = i (i &gt;= 0, i++)。这相当于冲突时，从冲突的地址+i，i从0递增，直到找到一个空的位置插入。如下是对于一个长度为10的散列表插入[89, 18, 49, 58, 69]时的情况。解决冲突的函数是f(i) = i。 第一次冲突是在插入49时出现冲突(hash(x) = x)，根据冲突解决公式,h(49)=(hash(49) + 1) mod 10时。冲突解决，结束，49放入该位置。第二次是插入58时出现冲突，h(58) = (hash(58) + 3) mod 10时。冲突解决。由上可知，每次冲突出现时，只需要沿着冲突的位置继续向下寻找可用位置，直到解决冲突即可。只要表足够大，总可以找到一个空位置。但是可能花费较多的时间。另外，占据的单元会开始形成一些区块，其结果称为一次聚集。当出现冲突后，可能会需要多次试选才能解决冲突。 可以得到证明，（证明较为复杂）。使用线性探测，预期探测次数对于插入和不成功查找约为：12(1+1(1−λ)2)\\frac{1}{2} (1 + \\frac{1}{(1- \\lambda)^2})21​(1+(1−λ)21​)，而成功的查找来说则是12(1+11−λ)\\frac{1}{2} (1 + \\frac{1}{1- \\lambda})21​(1+1−λ1​)。则插入与不成功查找的需要相同的次数，成功查找的次数比不成功查找的平均花费时间较少。 如果λ=0.75\\lambda = 0.75λ=0.75，则上述公式预计线性一次插入需8.5次探测，如过0.9，则需要50次探测。由此可以看到，如果表有超过一半被装填满的时候，线性探测法不是一个好的方法。 5.4.2 平方探测法 平方探测法是为了解决线性探测法的一次聚集问题。较为流行的选择f(i)=i2f(i) = i^2f(i)=i2，这相当于冲突时，加i2i^2i2，i从0开始递增，如下图，当49与89冲突时，放入0位置。下次58放入时，则按公式依次选择后，放入2位置。 对于平方探测法，一旦表的填充超过一半，则不够好。特别的，如果表的大小不是素数，在被填充一半之前，就不能一次找到空的单元了，证明如下。 定理5.1：如果使用平方探测法，且表的大小是素数，那么当表小于一半的时候，总能够插入一个元素。 证明：采用反证法 令表的大小TableSize是一个大于3的素数，证明前TableSize/2个备选位置是互异的。h(x)+i2(modTableSize)h(x) + i^2(mod \\quad TableSize)h(x)+i2(modTableSize)和h(x)+j2(modTableSize)h(x) + j^2(mod \\quad TableSize)h(x)+j2(modTableSize)是这些位置的其中两个，其中0 &lt;= , j &lt;= TableSize/2 (注意会向下取整，且tableSize是素数)。为推出矛盾，我们假设前两个位置相同，但i≠ji \\ne ji​=j，于是有 h(x)+i2=h(x)+j2(modTableSize)h(x) + i^2 = h(x) + j ^2 \\qquad (mod \\quad TableSize) h(x)+i2=h(x)+j2(modTableSize) i2=j2(modTableSize)i^2 = j^2 \\qquad \\qquad \\qquad \\qquad (mod \\quad TableSize) i2=j2(modTableSize) (i−j)+(i+j)=0(modTableSize)(i-j) + (i + j) = 0 \\qquad (mod \\quad TableSize) (i−j)+(i+j)=0(modTableSize) 由于TableSize是素数，要么i - j = 0，要么i+j=0。由于i，j互异，则第一个选择不可能，又因为0 &lt;= i，j &lt;= tableSIze/2，则第二个选择不可能。从而，前tableSize/2个备选位置都是互异的。则推出如上定理5.1。 即使表的填充位置只比一半多一个，则也可能插入失败。同时删除操作不能执行，因为相应的单元可能已经引起冲突，元素绕过它存在了别处，那么所有剩下的contains操作都会失败，因此探测表散列需要惰性删除， 探测表散列的大部分实现如下，此处不使用链表数组，使用单元数组HashEntry，其每一项有下列三种情形： null 非null，且该项是活动的（isActive 为true） 非null，且该项已被标记删除（isActive 为false） 平方探测法的实现（展开） ps: 判断是否时素数isPrime()方法，平方探测findPos()具体后移动平方的实现方法，这两个方法经典。 平方探测法解决了一次聚集，但是散列(计算到插入同一位置)到同一位置时，将继续往后探索相同的备选单元。这称为二次聚集。下面的双散列将解决这个问题，代价是要计算一个附加的散列函数。 5.4.3 双散列 双散列简单来说就是采取两个散列函数，其中一个散列计算具体的落入的位置，第二个散列是在冲突后，要从冲突的位置移动的步长。例如 hash1(x)=x mod tableSizehash_1(x) = x \\ \\ mod \\ \\ tableSizehash1​(x)=x mod tableSize（tableSize必须为素数），hash2(x)=R−(x mod R)hash_2(x) = R - (x \\ mod \\ R)hash2​(x)=R−(x mod R)，（R必须为素数）。 这里取tableSize = 10（计算方便），R = 7（小于tableSize 的素数）。首先89存入，下标9的位置没有冲突，直接存入，不计算散列函数2。假设再49插入时计算散列函数1，发现插入位置9发生冲突，需要计算散列函数2，hash2(49)=7−(49 % 7)=7hash_2(49) = 7 - (49 \\ \\% \\ 7) = 7hash2​(49)=7−(49 % 7)=7。从9开始，移动7个步长，所以移动到6的位置。"},{"title":"散列函数与分离链接法","date":"2022-04-10T05:24:41.000Z","url":"/2022/04/10/%E6%95%A3%E5%88%97%E5%87%BD%E6%95%B0%E4%B8%8E%E5%88%86%E7%A6%BB%E9%93%BE%E6%8E%A5%E6%B3%95/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第五章5.2与5.3节读书笔记 5.1 散列 理想的散列是只包含固定大小的数组， 通常查找是对某个数据域进行的，这部分叫做关键字(key) 每个关键字按照一定规则，均匀的映射到整个数组中。这个映射叫做散列函数 优秀的散列函数，能够将映射冲突的可能性降低到最小 5.2 散列函数 如果输入的关键字都是整数，则一般的简单映射函数就是使用key % tableSize，直接取模。同时保证表的大小为素数，是一个好得做法。但是通常得关键字都是字符串。则散列函数有以下方法可以考虑。 5.2.1 散列函数实现方案一 把字符串得ASCII码或者Unicode码的值相加。 以上函数，实现简单，计算方便，但是如果表很大，则表的的高位利用率较低，导致冲突率增大。 假设表的大小是一个素数：tableSize = 10007，并假设所有关键字至多8个字符(ASCII字符)，则该散列函数只能计算得到 0~1016（127*8）范围内的值。之后对tableSize 进行取余操作，导致1017之后的数是一定取不到的。从而分配不到高位的数组上去。 Java的散列表如HashMap等只会进行扩容，并不会缩小数组，如果采用ASCII码方案，HashMap的数组扩容后，使用不满，可能导致上述的情况发生。 5.2.2 散列函数实现方案二 假设key至少有三个字符，只考察前三个字符，将ASCII码乘起来得到一个整数 值27表示ASCII字符加一个空格，第一个字符就是本来的值，第二个字符是27 * 原值，第三个字符是27*27*原值。假设在完全随机的情况下，则3个字符的组合有19683种组合的可能。大于tableSize = 10007，则可以均匀分布。但是单词是有一定规律的，并不是均匀分布的。根据统计单词的前三个字母只有2851种组合，所以这种方法还是不适合。 Java的HashMap的数组最大为2302^{30}230，如果采用这种方案，最大可能需要所有计算和大于2302^{30}230的情况，需要7位的情况。 5.2.3 散列函数实现方案三 所有字符参与计算，计算∑i=0keySize−1Key[i]∗37i\\sum_{i=0}^{keySize - 1} Key[i]* 37^i∑i=0keySize−1​Key[i]∗37i，使用horner法则 计算一个37的n次多项式,37是一个质数。 根据horner法则计算一个37的多项式：例如：hk=k0+37k1+372k2h_k = k_0 + 37k_1 + 37^{2}k_2hk​=k0​+37k1​+372k2​，则根据horner法则可以转为：hk=((k2)∗37+k1)∗37+k0h_k = ((k_2) * 37 + k_1)*37 + k_0hk​=((k2​)∗37+k1​)∗37+k0​，可以简化计算复杂度。将其扩展到n项式 改散列函数基本可用，且实现简单。但是如果关键字特别长，则计算耗时特别多，一个行之有效的方法是只取奇数位置的字符串进行计算。不能只取部分的原因是，例如地址之类的，前半部分都是一样的。 5.3 哈希冲突之分离链接法 将散列到数组同一个位置上的所有元素都保留到同一个列表中。并连接到数组对应下标上的位置(数组中并不存储元素，只存储于列表) 5.3.1 具体操作 为简化操作，这里假设关键字是前10个完全平方数，并假设散列函数是hash(x) = x mod 10（表的大小不是素数(是10)，这里是为简化操作）。 先计算出hash，确定应该是数组的哪个下标的位置，然后遍历该下标的链表。如果执行插入，则查看当前插入的元素是否已经在链表上，不在则将值插入到链表头(最近操作的值，在未来的使用概率越大，可以加快查找)。 Jdk8的hashMap从之前的头插法改为尾插法，是为了解决多线程下，hashMap扩容时rehash时导致的链表成环的问题(并发请用correntHashMap)。jdk8及之后改为了尾插法。 本次实现的对象，必须实现equals方法于hashCode方法。hashCode用来计算判断应该链在哪条链表下，equals用于在hsah冲突后判断是否时同一个对象。如下是一个实现。 链接法的大部分实现 装填因子λ\\lambdaλ：散列表中的元素个数与数组大小的比值 上例的装填因子λ\\lambdaλ=1.0，链表的平均长度为λ\\lambdaλ(计算方法如上定义，平均每个列表有多少个元素)，一次平均查找需要1+λ/2\\lambda / 2λ/2。由此可以得出，表大小对查找效率基本无影响，影响较大的是装填因子。分离散列的一般做法是让λ\\lambdaλ = 1，"},{"title":"Debian11安装playwright依赖缺失问题解决","date":"2022-04-10T03:53:09.000Z","url":"/2022/04/10/Debian11%E5%AE%89%E8%A3%85playwright%E4%BE%9D%E8%B5%96%E7%BC%BA%E5%A4%B1%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","tags":[["debian","/tags/debian/"]],"categories":[["linux","/categories/linux/"]],"content":"最近的在Debian11系统上安装playwright时出现安装问题，网上的解决方案较少(几乎没有)，本篇文章是记录我解决方案的步骤。 本篇文章写于2022年04月，以下只针对当时情况。 开始按照提示，使用如下命令安装playwright（python环境下，py3 &gt; 3.7） 在安装后启动程序，报出install-deps出现问题，于是跟着提示执行安装install-deps。 如图接着报出依赖缺失问题，在仓库无法定位到几个包。接着查阅官方资料，发现官方对于linux系统，只主动支持了Ubuntu 18.04 and Ubuntu 20.04。Playwright系统要求官方文档 接着在另一个仓库下的issue下找到如下issue：Debian not supported by playwright · Issue #283，按照其解决方案，libjpeg-turbo8 和 libicu66这两个软件包不存在debian官方仓库中，需要去下载ubuntu的软件包，然后手动安装。即可解决，具体解决步骤如下： 本人使用的是Debian11，下载的是ubuntu20的软件安装包。 在pkgs.org下载libjpeg-turbo8_2.0.3-0ubuntu1_amd64.deb 在pkgs.org下载libicu66_66.1-2ubuntu2_amd64.deb 手动执行dpkg -i &lt;package&gt;.deb命令安装 再重新安装playwright install-deps即可安装成功 "},{"title":"floyd判圈算法","date":"2022-03-26T07:33:16.000Z","url":"/2022/03/26/floyd%E5%88%A4%E5%9C%88%E7%AE%97%E6%B3%95/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"floyd判圈算法（龟兔赛跑算法）简介 floyd算法判断链表是否有环 floyd算法计算环的长度 floyd算法寻找环的起点 floyd算法主要基于两个快慢指针，一个慢指针slow，快指针fast。慢指针每次移动1，快指针每次移动2。算法的时间复杂度为O(N) 1 判断是否有环 慢指针每次移动一步，快指针每次移动两步，若fast指向的对象与slow指针指向同一个对象，则说明有环。 证明：反证法: 如果没有环，则slow指针永远不可能追上fast指针，指向同一个对象。(此足以证明有环) 问题2：fast指针会越过slow指针不相遇吗？从而增加时间复杂度？ 不可能。假设fast越过slow，则slow = k + 1， fast = k + 2, 从而错过，往前推一步可知，他们必定在k的位置相遇。 时间复杂度：O(N)，在慢指针未走完一圈的时候，快慢指针必定能相遇。(如果无环，则O(N)不必证明) 证明： 快指针quick入环。之后，经过一段步骤，慢指针到达环的起点，准备入环。 此时，假设快指针距离慢指针x，如果在起点相遇，则x=0 设环的周长为L，那么之后就是快指针追赶慢指针，追赶距离为L-x 快指针的速度为每次2个距离，慢指针为每次一个距离，则快指针每次追赶2-1个距离，那么需要追赶(2-1) * (L-x) = L-x步。 在追赶L-x步的时间里，慢指针走了L-x的距离，由于x&gt;=0，所以在慢指针最多走完一圈(L)的距离时，必定已经相遇。 202. 快乐数 - 力扣（LeetCode）、(287. 寻找重复数 - 力扣（LeetCode)) 如果是快乐数，则最后会变为1，如果不是，则会进入几个数的循环。因此不为1时，判断是否有环即可。 2 求环的长度 当slow和fast相遇后，slow和fast必定在环上，只要让其中一个不动，另一个继续走，并计数，直到两者再次相遇，则可以得到环的长度 3. 求环的起点 如图为一个有环链表，对于该链表有如下定义： A为环的起点，S为链表的起点，B为slow与quick指针相遇的点。m为S到A的距离，n为A到B的距离 slow指针走过的所有节点为i，则quick指针必定走过节点2i。因为quick的速度是slow的2倍。 则有： 对于slow指针：i = m + n + aL (a为slow走过环的圈数，L为环的节点总数) 对于quick指针：2i = m + n + bL (b为quick走过的圈数，L同上) 第2点 - 第1点则有：i = (b-a)L， 则i 必定为L的整数倍。 带入第1点则有：m + n = (b - 2a) L，则m + n 必定为L的整数倍(b, a为整数，且m+n &gt; 0, 所以有 b-2a &gt; 0)，m+n是一个完整的环。 所以当从B点继续走m步，则必定停在A点（因为4，m+n是一个完整的环）。 但是m是多大，不清楚。此时，只需要一个指针从S点出发，另一个从B出发。如果走了m，S必定到达A点，B也必定到达A点，则当两个指针第一次相遇的时候，就是起点A。我们就不需要处理m的问题了。 142. 环形链表 II(LeetCode) 注：此题也可以用哈希表做，用一个指针遍历，将走过的节点存储起来，如果有环，则哈希表中必定能找到这个点，并且第一次找到的点就为起点（因为环的起点在前面）。如果到达节点末尾，则说明无环。 哈希表的时间复杂度也是O(N)，但是空间复杂度为O(N)，floyd判圈的空间复杂度为O(1)。"},{"title":"B-Tree","date":"2022-03-19T06:52:42.000Z","url":"/2022/03/19/B-Tree/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"B树概念简介，无代码实现 之前的各种二叉树都是存储在内存中的，而如果数据量过大，则需要将数据存储在磁盘中。然而磁盘的读取(I/O)速率相比内存而言较为低下。即使是AVL树，平均查找为时间为logNlogNlogN，对于1千万的数据，则大约需要24次对磁盘的访问。 4.7 B-Tree B树是一棵自平衡的多路平衡查找树，一棵的M叉B树的最坏查找时间复杂度为logM2Nlog_{\\frac{M}{2}}{N}log2M​​N。M(叉)阶B树具有如下特点： 所有数据都存储在树叶上，(其他节点只承担索引的作用)。 非叶子节点，存储最多M-1个关键字(索引) 如果根不是叶子节点，则根的子节点为[2, M]个 每个非叶子节点的子节点个数在[M/2, M]个，向上取整。 所有叶子节点都在同一高度。 所有叶子节点具有[L, L/2]个数据项(L不一定=M ) 4.5.1 B树的插入 若树叶没有满的情况下，直接插入即可。较为复杂的插入情况： 1、叶子满但能够分裂 值55想要插入下图，该树叶已满，此时在满足树叶具有[L, L/2]的情况下，可以将树叶平均分裂成两个树叶后插入。这种插入变化情况是较少的。因为一次插入，就能保证下L/2次不会分裂。 2. 叶子满不能分裂父分裂 值40想要插入时，插入位置树叶已满，同时父节点也已满（节点上最多具有M-1个个索引），可以将父节点分裂。（如果分裂后，父父节点满，则同时继续向上分裂），如果继续分裂到树根，如果继续分裂，则会的到两个树根，此时只能将树根分裂，并给他们建立一个新的树根（这是允许树根只有两个子节点的原因）。 这是B树增加高度的唯一方式。 4.5.2 B树的删除 1. 删除后可以从兄弟节点借 如果叶子节点的值删除后，节点数量值小于L/2，但是相邻兄弟节点大于L/2，则可以从兄弟节点借。 2. 删除后与兄弟节点合并 兄弟节点也只有L/2，那么可以和兄弟节点合并，同时父节点会失去一个儿子。如果父节点失去子节点后也少于，则向兄弟节点借，如果不行，则继续与兄弟节点合并。。。，如果这个操作进一步导致根只有一个子节点，那么删除根，并让这个子节点作为根。 这是B树降低高度的唯一方式。 "},{"title":"伸展树(Splay)","date":"2022-02-27T08:40:16.000Z","url":"/2022/02/27/%E4%BC%B8%E5%B1%95%E6%A0%91Splay/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"伸展树简介 4.5 伸展树 本质是一颗二叉查找树，在查找后，通过AVL的旋转操作，将查找的那个节点，旋转到root节点位置，达到将经常查找的节点置于root节点附近的目的，减少查询次数。 伸展树保证从空树开始连续M次对树的操作最多花费O(Mlog⁡N)O(M \\log N)O(MlogN)，但是不保证最坏的情况下时间复杂度为O(log⁡N)O(\\log N)O(logN)，m次伸展操作的均摊时间效率O(Mlog⁡N)O(M \\log N)O(MlogN)。 即使只读访问，每次访问后，其结构也会发生变化，因此在多线程下，其需要额外的维护。 4.5.1 一个简单的伸展想法 假设我们想查找的是k1，则从k1开始，自底向上的去操作，每次和他的父节点进行单旋转，将k1旋转上去(这个操作会将k1的父节点旋转下来，k1旋转上去)，直到将k1旋转到root节点。这样的操作虽然可以将k1旋转上去，但是其会将以前比k1靠近root的节点推到k1之前那么深，违背了最近查找节点置于顶部的逻辑。 4.5.2 正确的伸展 正确的旋转，是每次旋转都基于AVL的旋转操作，将查找节点K1旋转到root节点。主要基于以下两种操作 zig-zag(之字形) 要将x旋转上去，g、p、x组成之字形，先将x旋转到p上，再将x旋转到根节点即可。 zig-zig(一字型) g、p、x组成一字型，先将p旋转上去，再将x旋转上去即可。 实例： 使用如下示例，对k1进行操作： 示例原图： 进行一次zig-zag旋转： 进行一次zig-zig旋转： 4.5.3 自顶向下的伸展树 在自底向上的伸展树中，我们需要求一个节点的父节点和祖父节点，在实现的过程中需要使用栈来保存访问路径进行回溯，这种伸展树难以实现，自顶向下可以只使用O(1)的存储方式，实现一样的效果。 TODO : 该章节为书本第十二章实现，暂定之后实现 "},{"title":"Java小记","date":"2022-02-26T14:44:22.000Z","url":"/2022/02/26/Java%E5%B0%8F%E8%AE%B0/","tags":[["java基础","/tags/java%E5%9F%BA%E7%A1%80/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"主要记录不常用的 java 用法 1 数组转List 2 List转数组 "},{"title":"写于博客一周年之际","date":"2022-02-01T14:33:04.000Z","url":"/2022/02/01/%E5%86%99%E4%BA%8E%E5%8D%9A%E5%AE%A2%E4%B8%80%E5%91%A8%E5%B9%B4%E4%B9%8B%E9%99%85/","categories":[["站点相关","/categories/%E7%AB%99%E7%82%B9%E7%9B%B8%E5%85%B3/"],["博客相关","/categories/%E7%AB%99%E7%82%B9%E7%9B%B8%E5%85%B3/%E5%8D%9A%E5%AE%A2%E7%9B%B8%E5%85%B3/"]],"content":" 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 您好, 这里需要密码. "},{"title":"回溯算法","date":"2021-11-14T11:37:13.000Z","url":"/2021/11/14/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"回溯(backtrack)简介 1. 什么是回溯法 回溯(backtrack)是按条件沿着树的深度去搜索，直到达到满足目标条件或不再可能达到目标，就回退一步树的深度，选择树的另一个分支，这种走不通就退回的换分支技术为回溯。 回溯的本质是一个穷举的深度优先搜索(DFS)，每一种深搜都会对应一棵树，其时间复杂度较高，与穷举的区别在于满足条件或者知道后面不可能满足条件后，就进行回退，寻找另一种可能的解。其降低了重复的穷举的步骤，时间复杂度比穷举低。 2. 什么情况需要回溯 当只需要最优解时与最终解时，很容易想到贪心与动态规划，但是一旦要给出所有可能的解，这时就应该使用回溯了。 3. 回溯模板(java) 4. 名词释义 回溯：搜索到结果后，撤销上一步的搜索，进行另一个可能结果的下一步搜索 剪枝：在不可继续搜索的情况下，绝对不可能满足目标情况下，提前return，触发递归父级的回溯，从而提前回溯。 记忆集：有时结果不需要重复的，这时可以用set存储结果，或者boolean数组标记对应的下标是否被使用，避免重复使用。 排序：由于回溯本质是一个优化过后的穷举，其时间复杂度较高，因此在处理之前，可以考虑对其进行O(NlogN)O(NlogN)O(NlogN)时间复杂度排序，由于时间复杂度只取最高的，因此该时间复杂度可以忽略不记。 5. 例子 5.1 LeetCode40 组合总和 II 给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的每个数字在每个组合中只能使用一次。 注意：解集不能包含重复的组合。 例：输入: candidates = [10,1,2,7,6,1,5], target = 8, 输出: [ [1,1,6], [1,2,5], [1,7], [2,6] ] 5.2 LeetCode46 全排列 给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。 例：输入：nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] "},{"title":"二分查找的细节实现","date":"2021-10-31T06:37:15.000Z","url":"/2021/10/31/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%9A%84%E7%BB%86%E8%8A%82%E5%AE%9E%E7%8E%B0/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"二分查找的一些细节 1. 什么是二分查找 对于已经排序的表(假设该表是升序)，，假设目标值在闭区间[l, r]中， 每次将区间长度缩小一半，当l = r时，我们就找到了目标值。 2. 二分查找容易遇到的问题 二分查找原理简单，但是如果细节处理不好，容易出现错误答案，甚至是死循环的结果。网上给出的模板甚多，这里只给出Y大的模板。如下 3. 模板 原模板是C++版，如下已改为java版。 3.1 给出要查找数的左边界 如要查找升序数组中数4第一次出现的位置：[3, 3 , 4, 4, 4, 4, 4, 6, 8, 9]，结果应该为2； 如查找升序数组中第一个大于4(大于4的数中的左边界)的数：[3, 3 , 4, 4, 4, 4, 4, 6, 6, 8, 9 ]，结果应该为7; 注意第二种情况，并不是找4，找大于4的数，所以是大于4的数左边界。 当我们将区间[l, r]划分成[l, mid]和[mid + 1, r]时，其更新操作是r = mid(取被划分的左区间)，或者l = mid + 1(取被划分的右区间)，计算mid时不需要加1。 3.2 给出要查找数的右边界 如要查找升序数组中数4第最后一次出现的位置：[3, 3 , 4, 4, 4, 4, 4, 6, 8, 9]，结果应该为6； 如查找升序数组中最后一个小于4(小于4的数当中的右边界)的数：[3, 3 , 4, 4, 4, 4, 4, 6, 6, 8, 9 ]，结果应该为1; 注意第二种情况，并不是找4，找小于4的数，所以是小于4的右边界。 当我们将区间[l, r]划分成[l, mid - 1]和[mid, r]时，其更新操作是r = mid - 1或者l = mid，此时为了防止死循环，计算mid时需要加1。 4. 总结 4.1 如何选择模板 假设答案为N, 满足条件的数为o，不满足条件的数为x， 当数组为xxxxNoooo，这时答案为所有符合条件的值的最左边，所以应该使用第一种左边界的模板。 当数组为oo0oNxxxx，这时答案为所有符和条件的值的最右边，所以应该使用第二种右边界的模板。 4.2 记忆 确定左边界模板： 左边界：mid = (l + r) &gt;&gt; 1 满足条件选左子表，if(check(mid)) { r = mid } ; check满足的条件下，直接=mid，不需要+1。 不满足条件，l = mid + 1；(如果是要右区间，l = mid + 1；如果要左区间，r = mid - 1)。 确定右边界模板： 左边界：mid = (l + r + 1) &gt;&gt; 1 满足条件选右子表，if(check(mid)) { l = mid } ; check满足的条件下，直接=mid，不需要+1。 不满足条件，r = mid - 1；(如果是要右区间，l = mid + 1；如果要左区间，r = mid - 1)。 "},{"title":"二叉查找树与AVL树","date":"2021-10-23T08:53:09.000Z","url":"/2021/10/23/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91%E4%B8%8EAVL%E6%A0%91/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第二章4.3与4.4节读书笔记 4.3 二叉查找树 树的节点存储数据，一棵非空树要成为查找树，则对于任意节点x有：x的左子树都小于它，右子树节点都大于它。 二叉查找树的平均深度是O(logN)O(logN)O(logN)，证明可网上查询。可以使用递归实现，不必担心栈溢出。或见4.3.5小节 如下是一个二叉查找树的实现，其中BinaryNode是一个内部类，用来实现节点。 二叉查找树主代码实现(点击展开) 4.3.0 节点元素的比较实现 二叉查找树是有序的，因此必须使存储的元素是可以比较的，要使一个类是可以比的，有两种实现方式，1种是实现Comparable接口，另一种是令其传入Comparator比较器。这里选择了第二种，通过构造方法传入比较器。如果没有传入比较器，则内部将类强转为Comparable的，如果是不可比的，这时会抛出异常。(因为查找树是必须有序的，所以不可比也应该抛出异常)。 4.3.1 contains方法 该方法返回是否包含某个x元素，返回true或false，如果树t是空集，则返回false，如果x比t小，则继续查找左子树，否则继续查找右子树，直到查找到一个节点为null的点，说明没有。这使用递归实现。完整实例77-101行。 4.3.2 findMin与findMax方法 此两个方法，分别返回树种的最小的节点与最大的节点。对于最小节点，从root节点开始，向左子树查找，只要有左儿子就向左进行，如果左儿子节点为null，说明该节点最小元素。对于最大节点，从root节点开始，向右子树查找，只要有右儿子就向右进行，其余同查找最小节点。完整实例103-122行。 findMIn的实现使用的尾递归，即在尾部只实现对自身的递归调用，而且无其他处理，尾递归一把会被编译器优化，但是建议写成findMax的循环。 4.3.3 insert方法 该方法实现了在树中插入一个元素，然后返回该树的root节点(通过该节点可以获取到整棵树)。由于该树不是平衡的二叉查找树，该方法使用了简单的将将元素插入到叶子节点末端。如果插入的节点比root节点小，则继续与左子树的root节点比较，重复该步骤，直到某个叶子节点，与该叶子节点比较，如果小于，获取该叶子节点的左子节点，如果节点为null，则在null的地方插入；如果大于，获取该叶子节点的右子节点，如果节点为null，则在null的地方插入。完整实例124-151。 该方法是一个递归实现，注意递归较难理解，建议手动推导递归理解，理解每一层递归出栈的数据，后续怎么接收。以及最终结果返回的t的数据的具体含义。 4.3.4 remove方法 如果要删除的节点是叶子节点x，则直接删除，如果x只有一个子节点，则直接将x的子节点移动到删除的节点x即可。如果x有两个子节点，则将右子树的最小节点移动上去，然后对于右子树，继续将移动上去的元素删除，直到节点为null，则代表子树要删除的元素为null，此时跳出递归。 删除的节点4只有一个子节点：直接将子节点3移动到删除的节点即可。(将节点2的指针指向子节点) 删除的节点2两个子节点：将2的值改为右子树的最小的元素3，(注意，此时的原本的3的元素节点并没有删除)，然后将右子树中的3的节点按照此逻辑递归删除。 如果删除的次数不多，则使用惰性删除，当元素被删除时，只是被标记删除，仍然留在树中。 4.3.5 平均查找深度 树的节点平均深度为O(logN)。一棵树的所有节点的深度的和为内部路径长。 (如上图4-23：(6-&gt;2) + ((6-&gt;2) + (2-&gt;1)) + ((6-&gt;2) + (2-&gt;4)) + ((6-&gt;2) + (2-&gt;4) + (4-&gt;3)) + (6-&gt;8) = 9路径长 深度计算：1 + (1 + 1) + (1+1) + (1+1+1) + 1 = 9路径长 令D(N)是具有N个节点的树T的内部路径长，则D(1) = 0。一棵N节点的树由一棵i节点的左子树和一棵（N-i-1）节点的右子树组成。则D(N) = D(i) + D(N-i-1)，但是因为在原树中，左右子树的所有节点深度会被加一，因此需要加 N - 1。则递推公式： D(N)=D(i)+D(N−i−1)+N−1D(N) = D(i) + D(N-i-1) + N - 1 D(N)=D(i)+D(N−i−1)+N−1 对于二叉查找树，所有子树大小都等可能出现，则有D(i)与D(N-i-1)的平均值是(1N)∑j=0N−1D(j)(\\frac{1}{N}) \\sum_{j=0}^{N-1}D(j)(N1​)∑j=0N−1​D(j)。于是有 D(N)=2N[∑j=0N−1D(j)]+N−1D(N) = \\frac{2}{N}[\\sum_{j=0}^{N-1}D(j)] + N - 1 D(N)=N2​[j=0∑N−1​D(j)]+N−1 该值的解，可以的到平均值D(N) = O(NlogN) 4.4 AVL树 AVL是一棵自平衡的二叉查找树。 平衡：每个节点的左子树与右子树高度最大差为1。即 ∣H最高−H最低∣&lt;=1|H_{最高}-H_{最低}| &lt;= 1∣H最高​−H最低​∣&lt;=1，对于空树，高度定义为0 可以粗略证明，一棵AVL树的高度最多为1.44log(N+2)−1.3281.44log(N+2) - 1.3281.44log(N+2)−1.328。但实际高度只略大于log(N)。对于最少节点一棵高度为9的树，其左子树高度为7，右子树高度为8。在高度h的树中。最少节点S(h)=S(h−1)+S(h−2)+1S(h) = S(h-1) + S(h-2) + 1S(h)=S(h−1)+S(h−2)+1。对于h=0，S(h) = 1；h=1,S(h) = 2，函数S(h)与斐波那契数列相关。因此推导出上面的高度。 如上图，左图的左子树的高度为3(3-&gt;4-&gt;2，叶子节点3高1，4高2，2高3)，右子树的高度为2(7-&gt;8)，差为1。右图的左子树高度为3，右子树的高度为1，相差为2，不是AVL树(叶子节点的高度为0，注意与深度的区别)。‘可以简单的看作是两棵子树的最大深度相差为大于1’。 除去插入操作外(删除操作是惰性删除，不删除，只标记删除)，所有的对树的操作时间复杂度皆为O(logN)，因为插入操作会破坏树的平衡，这时需要进行旋转操作来维持树的平衡。 当一个节点插入后，任意两棵子树的高度差为2，只有插入点到根节点的平衡会被打破，因为只有这些节点的子树发生了变化。把必须平衡的节点记为a，失去平衡的情况可能会有以下四种： 对a的左儿子的的左子树进行一次插入，失去平衡，左左（LL）。 对a的左儿子的的右子树进行一次插入，失去平衡，左右（LR）。 对a的右儿子的的左子树进行一次插入，失去平衡，左左（RL）。 对a的右儿子的的右子树进行一次插入，失去平衡，左左（RR）。 情况1是情况4的镜像对称，该情况可以通过单次旋转完成。情况2是情况3的镜像对称，该操作发生在‘内部’的情形，需要通过双旋转平衡。 4.4.1 单旋转 4.4.1.1 左左情况(右旋) 如上图，对于单旋转的情况1，节点k2k_2k2​不满足AVL平衡的性质。为使树平衡，我们需要把节点X向上移动一层，节点Z向下移动一层。将树想象为灵活有重量的，现在拿住K1K_1K1​节点()，K1K_1K1​成为根，因为K2&gt;K1K_2 &gt; K_1K2​&gt;K1​，所以K2K_2K2​变成K1K_1K1​的右孩子。子树Y中的元素都大于K1K_1K1​，小于K2K_2K2​，所以可以将其放置到K2K_2K2​的左孩纸的位置。 如下图是一种实际情况的处理：左左 该平衡二叉树插入6后，对8而言，左子树高度为2，右子树高度为0(不存在)，相差为2，只对6、7、8而言，拿住7，进行一次右旋。(树原本是平衡的，被破坏平衡后，先处理较小子树的不平衡情况，所以这里只处理8子树的情况)。 4.4.1.12右右情况(左旋) 情况4是情况1的一种镜像对称(优先处理子树的不平衡，这里K2K_2K2​的子树是平衡的，是对K1K_1K1​不平衡，对K1K_1K1​是右右情况)。实例略。 4.4.2 双旋转 4.4.2.1 左右单旋转 左右的情况： 如上图，子树Y比子树Z高2层，将其抽象成如右图所示地3个连接点与4棵子树，B、C只比D深1121\\frac 12121​ ，把K2K_2K2​重新作为根，K1K_1K1​比K2K_2K2​小，因此作为子节点，同样K3K_3K3​作为右节点。 PS：对于左右的情况，可以先左旋，再右旋(操作次数会增加)，如下图(这里假设插入到B)： 下图有误，是在K2K_2K2​的节点下插入，应该只有B或者C，且插入的高度为1，但是对旋转逻辑无影响。 同样的对于右左的情况： 右-左 双旋转实例 Avl树主代码实现(点击展开) 打印树中的元素，测试用(点击展开) "},{"title":"初识动态规划","date":"2021-10-17T07:26:00.000Z","url":"/2021/10/17/%E5%88%9D%E8%AF%86%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","tags":[["算法","/tags/%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["算法","/categories/cs%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/"]],"content":"动态规划简介 1.什么是动态规划 动态规划一般简称dp，动态规划求解的问题一般可以把复杂的问题拆分一个个子问题，最终通过求解最优子结构，来得到问题的解。 2. 如何识别动态规划题目 问题一般只会要求求出最终解或最优解，但是可以穷举出所有可能的结果集，并且穷举的过程中出现了大量的重复子计算(将在例题中说明)，。如最长递增子序列、最小编辑距离、背包问题、凑零钱问题等等，都是动态规划的经典应用场景。 动态规划可以很容易看出用递归实现，但是递归的存在重复的递归，使得时间复杂度很高，这时递归不被允许使用，(可以使用记忆集(List或map)，将之前计算过的答案记下来再直接使用，避免重复计算，降低时间复杂度，注意，括号内的类容不是动态规划)。 3. 动态规划解题步骤 当识别出可以使用动态规划后，先尝试去写出状态转移方程。 最终解：画出递归树，root节点即为要求出的最终解，找到最优解/最终解可以如何由子问题得出，以此确定状态转移方程。(最简单的是一维数组，有二维甚至多维数组)。 最优解：假设i-1处的最优解为dp[i-1]，推出dp[i]处的最优解的所有可能，一般使用Math.max或Math.min的到所有可能解的最优，与dp[i]处的解比较，得出最优解。 4.动态规划例题 4.1 青蛙跳台阶问题（斐波那契数列） 一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 n 级的台阶总共有多少种跳法。 分析(递归树略)： 台阶数为1：跳法：1种。跳：1。 台阶数为2：跳法：2种。跳：1 + 1、2。 台阶数为3：跳法：3种。跳：1+1+1、1+2、2+1。 台阶数为4：跳法：5种。跳：1+1+1+1、1+2+1、1+1+2、2+1+1、2+2。 可以看出，在找跳法时，是存在重复计算的。例如，台阶为3时，跳了1+1+1时，计算了跳到1的情况，这时1+2，又要计算一遍跳到1的情况(每次都要从台阶1跳)。 尝试写出转移方程：最终答案为n级台阶，那么n级台阶可以由n-1级台阶跳一级过来，也可以由n-2级台阶跳两级过来（如跳3级台阶，则可以从1级跳过来：这时跳法是1+2(如果跳1+1+1，则实际上从2级跳过来的，是重复计算，不应考虑，所以应从1直接跳到3，只能跳2级，原本只有一种跳法)，所以只有一种跳法；从2级跳过来：这时跳法是：1+1+1 (1+1 +1，前面的1+1是本来到2级台阶的方法，所以这是直接从2级台阶跳)与2+1。可以看到总跳法为两个子问题的和）。此题为求最终问题，所以得到状态转移方程： dp[n]=dp[n−1]+dp[n−2]dp[n] = dp[n-1] + dp[n-2] dp[n]=dp[n−1]+dp[n−2] 另外此题的递归方程也是该方程f(n)=f(n−1)+f(n−2)f(n) = f(n-1) + f(n-2)f(n)=f(n−1)+f(n−2)。可以很容易的写出递归求解，但是该递归的复杂度很高，时间复杂度为2n2^n2n，因为存在重复的递归计算。例如求f[n]时需要求解f(n-2)，再求解f(n-1)时，也需要求解f(n-2)。导致时间复杂度很高。(可以考虑使用记忆集存储)。因此不考虑，以下为动态规划解答。时间复杂度分析：O(N) 4.2 最大连续子序列和 给定一个数组，求该数组的最大连续的子序列的和。例如[-1,-2,5-3,8,-1]，则最大子序列之和为10 ：5+(-3)+8 分析： 从索引0开始穷举，一个个加，得到从索引0的最大和为7，注意，此时已经计算了一遍连续数字的和。 从索引1开始穷举，一个个加，得到从索引最大的和为8，此时又计算了一遍连续数字的和。 假设已经求出前面的dp[n-1]处的最大子序列和，这时如果dp[n]是正数，dp[n] = dp[n-1] + nums[n]，如果dp[n]是负数，肯定nums[n]单独更大，所以状态转移方程为：时间复杂度分析：O(N) dp[n]=max(dp[n−1]+nums[n],nums[n])dp[n] = max(dp[n-1] + nums[n], nums[n]) dp[n]=max(dp[n−1]+nums[n],nums[n]) "},{"title":"树与二叉树","date":"2021-10-09T08:15:33.000Z","url":"/2021/10/09/%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第二章4.1与4.2节节读书笔记 4.1 树 定义树的一种自然方式是递归。一棵树是N个节点和N-1条边的集合。 一棵树是一些节点的集合。可以是空集。若不为空，则由根节点r和0个或多个非空的字树T1，T2，T3，…，Tk组成，子树中每一颗根都被来自r的一条有向边连结。 树的术语定义： 子节点：若节点E有子树，则子树的根节点(如J)为E的子节点。 父节点：若节点E有子节点，则E为子节点(如J)的父节点。 节点的度：节点有子树棵树(子节点个数) 叶子节点：没有儿子节点的节点(度为0的节点)，如图节点P等。 兄弟节点：具有相同父节点的节点互为兄弟节点。如P节点与Q节点。 节点层次(level)：本书称节点nin_ini​的深度，从根节点到nin_ini​的路径长，因此根节点层次(深度)为0. 树的深度(注意是树)：其他书特指：根节点到最远叶子节点的路径长。根节点深度为0。 树的高度：最深的叶子节点高度为0，一棵树高等于根高。如E：深度为1，高为2。(其他书特指最大高度。即高度=深度)。 祖先与真祖先、后裔与真后裔：如果存在n1n_1n1​到n2n_2n2​的一条路径，那么n1n_1n1​为n2n_2n2​的祖先，n2n_2n2​为n1n_1n1​的后裔，如果n1≠n2n_1 \\ne n_2n1​​=n2​则n1n_1n1​是n2n_2n2​的真祖先，n2n_2n2​是n1n_1n1​的真后裔。 4.1.1 树的实现 节点存储数据，另有一些链，该节点的每一个子节点都有链指向它。由于不确定有多少链，因此采用其他解决方法，将每个节点的子节点都放在一个链表中。 如下是针对上述的一种实现(对应图4.2)。向下的箭头指向firstChild(第一儿子)的链，水平箭头指向nextSibling(下一兄弟)的链。null链未画出。如节点E有链指向兄弟F，另一链指向儿子I。 4.1.2 树的应用与遍历 所谓的序是指遍历时根的位置，如前序就是根左右，中序就是左根右(针对二叉树)，后序就是左右根 树的应用 多叉树的一种用法是UNIX与DOS系统的目录结构，如下图是UNIX文件的一个典型应用。 先序遍历展示所有目录： 先序遍历按照先根后左(子树)再右(子树)。例如上图某次的遍历实现。usr -&gt; mark -&gt; book - &gt; ch1.r -&gt; ch2.r -&gt; ch3.r -&gt; course(右子树) -&gt; cop3530 -&gt; fail -&gt; syl.r -&gt; spr -&gt; syl.r -&gt; sum -&gt; syl.r -&gt; junk(右子树) -&gt; alex… 该算法遍历每一个节点，显然先序遍历的时间复杂度为O(N)。 记忆口诀：根左右 后序遍历计算某树目录下的所有文件大小：括号内代表所占区块个数 要计算usr目录下的文件所占的存储大小，找出其所有子目录mark(30)、alex(9)、bill(32)的区块个数和为71，加上usr的区块个数和为1，最终为72。如果当前对象不是目录，size只返回当前对象的区块数，否则该目录占用的区块数被加到所有子节点(递归)发现的区块数中。usr:1(暂存) -&gt; chl.r:(3+1) -&gt; ch2.r(4+2) -&gt; ch3.r(6+4) -&gt; book(10+1) -&gt; syl.r(11+1)… 注意：以上暂存代表并未实现真正的遍历，因此遍历是从ch1.r开始的，ch1.r -&gt; ch2.r -&gt; ch3.r -&gt; book -&gt; syl.r -&gt; fall -&gt; syl.r -&gt; spr -&gt; syl.r -&gt; sum -&gt; cop3530 -&gt; course -&gt; junk -&gt; mark -&gt; junk -&gt; alex -&gt;work -&gt; grades… 记忆口诀：左右根 4.2 二叉树 如果一棵树，其每个子节点最多不超过两个儿子。在最坏的情况下二叉树可能会退化为一个链表 4.2.1 二叉树的实现 一棵二叉树最多有两个节点，因此只需要一个元素的信息(element)和到其他两个节点的引用(left与right)组成。 4.2.2 例子：表达式子树 如下图为一个表达式子树，树叶为操作数，其他节点为操作符，其操作都是二元的，(如果不是，孩子可能出现大于2的情况)。 中序遍历：如树的介绍左根右，递归产生带括号的左表达式，然后打印出再根的运算符，再递归产生一个带括号的有表达式，从而得到带括号的中缀表达式(一个括号代表一个子树)。得到：(a+b∗c)+((d∗e+f)∗g)(a + b * c) + ((d * e + f) * g)(a+b∗c)+((d∗e+f)∗g)。中缀表达式。 后序遍历：如树介绍的左右根，先递归的打印出左子树，右子树，再打印运算符，将的到a b c ∗ f + g ∗ +a \\ b \\ c \\ * \\ f \\ + \\ g \\ * \\ +a b c ∗ f + g ∗ + 。后缀表达式(逆波兰表达式)。 先序遍历：如树介绍的根左右，先打印出运算符，再递归打印出左子树和右子树。得到++a∗bc∗+∗defg++a*bc*+*defg++a∗bc∗+∗defg 。前缀表达式(波兰表达式)。"},{"title":"栈与队列","date":"2021-09-21T09:26:33.000Z","url":"/2021/09/21/%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第二章3.6与3.7节节读书笔记 3.6 栈ADT 3.6.1 栈模型 栈是插入和删除只能在末端的表，该位置叫栈顶(类似一个桶)。对栈的操作只有进栈(push)与出栈(pop)。 栈是一个后进先出(LIFO)表。我们对栈能进行的操作基本只有push和pop操作。位于栈顶的元素，是唯一直接可见(可访问)的元素。 3.6.2 栈的实现 栈是一个表，任何能实现表的的方法都能实现栈，给出两种流行的实现方法：一种使用链式结构，一种使用数组，二者均简化了在ArrayList和LinkedList的实现。 栈的链表实现 使用单链表，在表的顶端插入实现push，删除表顶端的元素实现pop，top操作获取表顶端的元素并返回值，有时pop与top合二为一。 栈的数组实现 数组的实现避免了链而且可能是最流行的解决方案。push模仿ArrayList的add操作，实现简单。与栈相关的操作是theArray和topOfStack，对空栈，topOfStack为-1(初始化操作)，当由元素x入栈时，topOfStack + 1，theArray[topOfStack] = x。 同理弹栈的时候返回theArray[topOfStack] ，之后topOfStack - 1。 上述操作皆以常数时间运行，再某些机器上push与pop都可以写作一条机器指令，现代化计算机将栈操作作为指令系统的一部分。 3.6.3 应用 平衡符号 编译器检查具有成对的符号(如大括号、括号)缺失引起的编译错误。例如[()]是合法的，但是[(])是错误的。对该算法的简单叙述如下： 将所有字符读入，如果字符是是一个开放符号(成对符号左边的)，就将符号入栈(注意是只入栈符号)。如果是封闭符号，当空栈时报错，否则将栈顶的元素弹出，如果弹出的不是对应的开放符号，则报错，如果读到文件尾，栈非空，则报错。该算法时线性的，且他是联机算法。 后缀表达式 在我们使用的四则运算中，我们都知道乘除优先，需要指定优先级时，可以使用括号，但这(中序表达式)对于计算机则非常不友好，于是有了后缀表达式或称逆波兰式。操作符号放在需要参与运算的数的后面，并且与他前面的数参与运算。他的一个显著的优点是不需要知道运算的优先规则。 例如表达式 6 5 2 3 + 8 ∗ + 3 + ∗6 \\ 5 \\ 2 \\ 3\\ + \\ 8 \\ * \\ + \\ 3 \\ + \\ *6 5 2 3 + 8 ∗ + 3 + ∗ 的含义：将6、5、2、3入栈，遇到+号，表示+号前面的3+前面的2弹栈，并将得到5入栈。再遇到8，8入栈，接着遇到*号，则*号前面的8与5的弹栈，并将8*5的结果40入栈。。。(即遇到数字就继续入栈，遇到四则符号就将前面的两个数弹栈，并将计算的结果入栈)。上式的计算结果如下。 ((((3+2)∗8)+5)+3)∗6=288((((3+2) * 8) + 5)+3)*6 = 288 ((((3+2)∗8)+5)+3)∗6=288 中缀转后缀表达式 日常使用的中缀表达式可以转为后缀表达式，之后方便计算机进行计算。 范例：a + b * c + (d * e + f) * g ====== a b c *+ d e * f + g *+ 逻辑： 初始化一个栈，用于存放运算符；初始化一个List用于存放数字。List为最终结果 如果遇到数字，则直接存入List 如果遇到运算符，则与栈顶的运算符比较，如果优先级比栈顶的高，则入栈，否则(同优先级或者低)将栈顶的运算符弹栈再存入队列，之后再将运算符与栈顶的元素继续比较，直到入栈。(优先级 ‘*’ = ‘/’ &gt; ‘+‘ = ‘-’)。注意运算符不与括号比较，直接入栈。 如果遇到左括号，则直接入栈，如果遇到右括号，则将栈顶的运算符依次弹出存入队列，直到遇到左括号(不判断栈空的情况：表达式错误)，弹出左括号。(注意括号只弹出，不输出) 如果传入数组遍历完毕，则依次弹出栈顶元素存入List。 3.7 队列ADT 3.7.1 队列模型 队列的入队发生在队列尾，出队出现在队首。类似排队，只能在队尾增加，队首删除。 3.7.2 队列的数组实现 队列的数组与链表都可以实现，都是O(1)的时间运行。如下是数组的实现。 顺序队列：初始时，head与tail指针同时指向0，每当新增元素，tail++，删除元素，head–。直到数组尾部。 循环队列：初始时，head与tail指针同时指向0，每当新增元素，tail++，删除元素，head–。如数组越界，则插入倒队首对应的位置。 "},{"title":"表与java中表的实现","date":"2021-07-11T08:42:17.000Z","url":"/2021/07/11/%E8%A1%A8%E4%B8%8Ejava%E4%B8%AD%E8%A1%A8%E7%9A%84%E5%AE%9E%E7%8E%B0/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第二章3.1到3.5节读书笔记 3.1 抽象数据类型 抽象数据类型(ADT)：是带有一组操作的一些对象的集合 对于集合ADT，可以有像添加(add)、删除(remove)、与包含(contain)这样的一些操作。也可以只要两种操作，并(union)和查找(find)。 ADT的实现一般取决与程序设计者，当ADT被程序设计者正确的实现后，使用该语言可以不必要知道他们如何实现。 3.2表ADT 形如A0,A1,A2,…,AN−1A_0,A_1,A_2,\\ldots, A_{N-1}A0​,A1​,A2​,…,AN−1​，这个表的大小为N，如果该表的大小为0，则该表称为空表，除空表外的任何表，AiA_iAi​后继Ai−1A_{i-1}Ai−1​(或继Ai−1A_{i-1}Ai−1​之后，i&lt;N)，并称Ai−1A_{i-1}Ai−1​前驱Ai(i&gt;0)A_i(i&gt;0)Ai​(i&gt;0)。 常用操作(不同的语言有不同的实现)： printList：java没有直接实现，如果是List，可以直接打印，因为其父类AbstractCollection重写了toString方法。 如果是数组，可以通过Arrays.toString(数组)，方法实现打印。 makeEmpty：如果是List，有clear()方法，将所有元素置为null。 find：找到某元素第一次出现的位置，jdk好像没实现 insert：jdk实现的是add方法，有重载，不指定index，则默认最后，可以指定index。 findKth：查找某个index下的元素，如果是List，有get(index)方法，数组则int[index]。 remove：移除某个index的元素 3.2.1表的简单数组实现 数组的实现，使printList可以用线性的时间O(N)执行，findKth则花费常数时间。插入和删除开销昂贵，在最坏的情况下，在索引为0的位置插入，需要将所有元素向后移动一位。而删除一个位置则需要将所有元素向前移动一位。两种操作的时间都为O(N)。但是如果所有元素都操作在表的高端(末端，数组有容量的情况下，否则需要昂贵的扩容)。添加和删除只需要O(1)的时间。 3.2.2简单链表 链表由一系列节点组成，这些节点在内存中可以不相连，每个节点均含有表元素和包含该元素后继节点的链 link(指针)，称之为next链。最后一个节点的next链为null。 执行printList与find(x)，可以从表的头的第一个节点开始使用后继的next遍历该表即可，这种操作和数组一样，是线性的时间。 remove方法通过修改一个next指针实现，insert方法使用new操作符从系统中新增一个节点，此后执行两次引用调整。如图所示，链表的插入与删除都只需要花费常数的时间。 双向链表：让每一个节点持有一个指向它在表中的前驱节点的链 3.3 Java Collections API中的表 表ADT是在Collections API中的实现数据结构之一。 3.3.1 Collections接口 Collection接口扩展Iterable接口(可迭代)，实现该接口的类可以拥有简单的for循环， 3.3.2 Iterator接口 实现Iterator接口的集合必须实现iterator接口方法，返回一个iterator，该iterator将当前位置的概念在对象内部存储。该iterator是java.util包中定义。 每次对next调用，都给出该集合的下一项，hasNext()用来返回是否存在下一项。对于实现Iterable接口的增强for循环，编译器会重写，将其转换为由迭代器iterator进行迭代。所以前面的print被编译器改写为。 iterator接口还有一个remove方法，该方法删除next返回的项，虽然Collection接口也有remove方法，但是Iterator方法有更多优点。Collecction的remove方法，必须要指定删除那一项，而Iterator可以在遍历的过程中删除。如果直接使用for循环remove集合中的某个元素，则会抛出异常，这时就应该使用迭代器的remove方法。 3.3.3 List接口与继承的类 List接口继承了Collection接口，如下包括其自己定义的一些重要的方法 List ADT有两种流行的实现方式，ArrayList是可变数组的具体实现，具有数组的特点，get与set花费常数的时间，add与remove的花费线性O(N)的时间(不在末端的情况)。LinkedList则实现了一种双向链表。具有一系列操作首尾位置的方法，其具有链表的特点，get的时间近似线性。 构造一个新的List 该构造，无论传入的是ArrayList还是LinkedList都是O(N)，每次都是在末尾添加。不考虑ArrayList的扩容。 在表的前端插入元素 该构造，对于ArrayList是O(N2)O(N^2)O(N2)，因为其每次插入花费时间O(N)，对于LinkedList则花费时间O(N) 求表中所有元素的和 对于ArrayList其时间为O(N)，LinkedList时间为O(N2)O(N^2)O(N2)，因为其每次获取元素需要O(N)的时间。如果使用增强for循环，则两个都是O(N)，将使用迭代器一直迭代下去。对搜索而言，两者都是低效的，contains与remove方法均花费线性时间。 3.3.4 LikedList中的remove方法 考虑如下一个例子，删除表中的所有偶数。表[6,5,1,4,2]，删除后表中仅有5，1两个元素。 对于ArrayList，其删除的操作是O(N)，不是，一个好策略，对于LinkedList，如果不使用迭代器则是O(N)(首先需要找到该元素才能删除)，如果使用迭代器，则一次删除为O(1)。 如果使用普通的while循环，那么对于ArrayList是O(N2)O(N^2)O(N2)的时间，对于LinkedList也是O(N^2)的时间。 如下，该方法使用了增强for循环(即使用了迭代器)，但是使用了collection的remove方法，该方法必须再次搜索该项，因此remove执行时间仍然为O(N)，总体时间为O(N2)O(N^2)O(N2)，并且同上，对增强for循环使用的基础迭代器中，collection的remove元素也是非法的 如下使用迭代器，对于LinkedList是O(N)的复杂度，对于ArrayList则依旧是O(N2)O(N^2)O(N2)的复杂度(remove后，数组必须整体向前移动) 3.3.5 ListIterator接口 该接口只能被List使用，其扩展了Iterator 3.4 ArrayList类的实现 此处手动实现一个MyArrayList，该类独立实现。将具有以下特点： 将保持基础数组，数组的容量，存储当前项数 将提供方法改变数组的容量，(将改变容量后的数组拷贝到新数组) 提供get与set实现 提供基本的例程，size()与isEmpty()实现，clear()实现，提供remove()，add() 实现Iterator接口，提供next，hasNext，remove。 3.4.1 基本类 该类不检测非法的迭代器remove方法。会在之后的3.5节实现。 基本类主代码实现(点击展开) 3.4.2 嵌套类与内部类 迭代器-内部类：可以使用，推荐这种(就是上面的实现) 迭代器-嵌套类：就是把内部类申明为静态的，同时指定泛型，构造函数传入外部参数，可以使用，但不推荐，使用上面的。故不再列出。 3.5 LinkedList实现 同上，此处将手动实现一个LinkedList MyLinkedList类本身，包含到两端的链、表的大小和一些方法 Node类，私有嵌套(静态内部)类，一个Node节点包含一个数据以及到前一个节点链和到下一个节点的链，还有构造方法 LinkedListIterator类，抽象了位置的概念，私有类，实现Iterator，提供next方法、hasNext和remove实现 3.5.1 基本类 该链表主要由Node节点组成，迭代器去遍历实现，迭代器存储当前节点的引用。该实现真实的链表前端额外创建一个节点，称为头节点，末端也额外创建一个节点，称为尾节点。使用这些节点的好处在于简化编码，删除头节点与尾节点都不再是特殊情况(删除算法也需要访问被删除的前一个节点)。 基本类主代码(点击展开) "},{"title":"原码-反码-补码","date":"2021-06-06T04:32:51.000Z","url":"/2021/06/06/%E5%8E%9F%E7%A0%81-%E5%8F%8D%E7%A0%81-%E8%A1%A5%E7%A0%81/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"问题：byte类型的127加上1，得到的结果是-128 一、原码 计算机只能存储、计算二进制数据，一个byte有8个字节。那要计算两个十进制的数据，需要先将十进制数据转换为二进制数据。 例十进制： 7+1=87+1=8 7+1=8 转换为二进制计算：8字节，高位补0 00000111+00000001=000010000000 0111 + 0000 0001 = 0000 1000 00000111+00000001=00001000 对于正数的计算，这个没有问题。但是对于负数如何表示？再去维护一个符号用于表示负数的代价过于高昂，于是采用了在8字节的最高位表示为1用于表示负数，只用7位表示计数。于是 -1 表示为 100000011000 000110000001。对于正数，不需要额外的处理，反码就是源码本身。 例十进制： 2−2=02-2=0 2−2=0 反码的出现不仅表示了负数，而且还把减法可以表示为加上一个负数，从而不再需要设计减法计数器电路。但是计算会出现如下问题： 00000010+10000010=100001000000 0010 + 1000 0010 = 1000 0100 00000010+10000010=10000100 转换为二进制可知，计算的结果为-4，计算出现了问题。 二、反码 为了解决这个问题，出现了反码。同样，正数的反码是其本身；对于负数，就是最高位的符号位不变，其余位置取反，例如-2​二进制是100000101000 001010000010，则其反码为111111011111 110111111101， 例十进制： 2−2=02-2=0 2−2=0 则二进制： 00000010原码+10000010原码0000 0010_{原码 } + 1000 0010_{原码 } \\quad 00000010原码​+10000010原码​ 00000010反码+11111101反码=11111111反码0000 0010_{反码 } + 1111 1101_{反码 } = 1111 1111_{反码 } 00000010反码​+11111101反码​=11111111反码​ 先转换为反码，再计算，得到的是反码的结果，但是要得到真正的结果，还需要再转为原码。 11111111反码−−&gt;10000000原码1111 1111_{反码 } --&gt; 1000 0000{原码 } 11111111反码​−−&gt;10000000原码 结果为-0，可见，结果是正确的，但是出现-0的结果需要处理。 三、补码 同样，为了解决出现-0的情况，出现了补码。同样,正数的补码是其本身；对于负数，负数的补码是其反码+1。例如，-2的二进制是100000101000 001010000010，则其反码为111111011111 110111111101，则其补码为111111101111 111011111110。 例十进制： 2−2=02-2=0 2−2=0 则二进制： 00000010原码+10000010原码0000 0010_{原码 } + 1000 0010_{原码 } \\quad 00000010原码​+10000010原码​ 00000010反码+11111101反码=11111111反码0000 0010_{反码 } + 1111 1101_{反码 } = 1111 1111_{反码 } 00000010反码​+11111101反码​=11111111反码​ 00000010补码+11111110补码=00000000补码0000 0010_{补码 } + 1111 1110_{补码 } = 0000 0000_{补码 } 00000010补码​+11111110补码​=00000000补码​ 计算十进制结果：由于最高位是0，则表示正数，补码是原码本身，所以原码为000000000000 000000000000，结果为0 四、已知补码求原码 已知某补码为 1111 1110，求原码 1.正数： 如果以0开头，则证明其为正数，原码就是补码本身，如 0000 0010的补码就是本身 2.负数： 如果以1开头，则证明为负数，先 将最高位不变，其余7位取反。 11111110补码−−&gt;取反100000011111 1110_{补码 } --&gt;取反 1000 0001 11111110补码​−−&gt;取反10000001 再+1，即可得到原码(-2)： 10000001+00000001=10000010原码1000 0001 + 0000 0001 = 1000 0010_{原码} 10000001+00000001=10000010原码​ 五、普通结果验证 5-3与3-5 1.运算1： 5+ (-3) (省略了反码的计算步骤) 原码：00000101原码+10000011原码0000 0101_{原码} + 1000 0011_{原码}00000101原码​+10000011原码​ 补码：00000101补码+11111101补码=00000010补码0000 0101_{补码} + 1111 1101_{补码} = 0000 0010_{补码}00000101补码​+11111101补码​=00000010补码​ 结果：00000010补码0000 0010_{补码}00000010补码​是正数，原码为本身，所以十进制为2. 2.运算2： 3+(-5) (省略了反码的计算步骤) 原码：00000011原码+10000101原码0000 0011_{原码} + 1000 0101_{原码}00000011原码​+10000101原码​ 补码：00000011补码+11111011补码=11111110补码0000 0011_{补码} + 1111 1011_{补码} = 1111 1110_{补码}00000011补码​+11111011补码​=11111110补码​ 结果：11111110补码1111 1110_{补码}11111110补码​是负数，原码为最高位不变，其余位取反再加1，则为：100000101000 001010000010，结果为-2。 六、-128问题 byte类型127+1 = -128 原码：01111111+000000010111 1111 + 0000 000101111111+00000001 补码：01111111+00000001=100000000111 1111 + 0000 0001 = 1000 000001111111+00000001=10000000 结果：-128没有原码与反码，只有补码，按照约定，补码为100000001000 000010000000则为-128。 七、延申： 实际上，现代计算机中的逻辑计算电路，都是按照补码来进行存储的。所以实际的计算过程中，直接使用补码。"},{"title":"数学基础与要分析的问题","date":"2021-04-05T08:54:53.000Z","url":"/2021/04/05/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E4%B8%8E%E8%A6%81%E5%88%86%E6%9E%90%E7%9A%84%E9%97%AE%E9%A2%98/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第一章2.1~2.3节读书笔记 1. 数学基础 1.1 定义 1 定义：如果存在正常数c和n0n_0n0​，使得N≥n0N \\ge n_0N≥n0​时，T(N)≤cf(N)T(N) \\le cf(N)T(N)≤cf(N)，则记为T(N)=O(f(N))T(N)=O(f(N))T(N)=O(f(N))。 释义：T(N)的增长率小于或等于f(N)。 2 定义：如果存在正常数c和n0n_0n0​,使得N≥n0N \\ge n_0N≥n0​时，T(N)≥cf(N)T(N) \\ge cf(N)T(N)≥cf(N)，则记为T(N)=Ω(g(N))T(N)=\\Omega(g(N))T(N)=Ω(g(N))。 释义：T(N)的增长率大于或等于g(N)。 Ω\\OmegaΩ 读作&quot;omega&quot;。 3 定义：T(N)=Θ(h(N))T(N)= \\Theta(h(N))T(N)=Θ(h(N))当且仅当T(N)=O(h(N))T(N)=O(h(N))T(N)=O(h(N)) 和 T(N)=Ω(h(N))T(N) = \\Omega(h(N))T(N)=Ω(h(N))， 释义：T(N)的增长率等于h(N)。 Ω\\OmegaΩ 读作&quot;omega&quot;。Θ\\ThetaΘ 读作&quot;Theta&quot;。 4 定义：如果T(N)=O(p(N))T(N) = O(p(N))T(N)=O(p(N))且T(N)≠Θ(p(N))T(N) \\ne \\Theta(p(N))T(N)​=Θ(p(N))，则T(N)=o(p(N))T(N) = o(p(N))T(N)=o(p(N))。 释义：T(N)的增长率小于p(N)。 读作&quot;小o&quot;。不同于大O，大O包含增长率相同的可能性。 1.2 法则 法则1：如果T1(N)=O(f(N))T_1(N) = O(f(N))T1​(N)=O(f(N))且T2(N)=O(g(N))T_2(N)=O(g(N))T2​(N)=O(g(N)),那么： T1(N)+T2(N)=O(f(N)+g(N))T_1(N) + T_2(N) = O(f(N) + g(N))T1​(N)+T2​(N)=O(f(N)+g(N)) T1(N)∗T2(N)=O(f(N)∗g(N))T_1(N) * T_2(N) = O(f(N) * g(N))T1​(N)∗T2​(N)=O(f(N)∗g(N)) 法则2：如果T(N)是一个k次多项式，则T(N)=θ(Nk)T(N)=\\theta(N^k)T(N)=θ(Nk) (T(N)的增长率与NKN^KNK相同) 法则3：对任意常数k，logkN=O(N)log^kN=O(N)logkN=O(N)，它告诉我们对数的增长非常缓慢。(logkNlog^kNlogkN 对数的k次方) 1.3 大O表示法 T(N)=Of(N)T(N)=Of(N)T(N)=Of(N) 例如T(N)=O(N2)T(N)=O(N^2)T(N)=O(N2)，(N平方级)，人们不说&quot;…级的&quot;，而说&quot;大O…&quot; 上界：当T(N)=Of(N)T(N)=Of(N)T(N)=Of(N)时，保证函数T(N)T(N)T(N)的增速不快于f(N)f(N)f(N)，因此f(N)f(N)f(N)是T(N)T(N)T(N)的一个上界。 下界：同上，T(N)T(N)T(N)是f(N)f(N)f(N)的一个下界。 如果T(N)=O(N)T(N)=O(N)T(N)=O(N)成立，则显然T(N)=O(N2)T(N)=O(N^2)T(N)=O(N2)成立，但T(N)=O(N)T(N)=O(N)T(N)=O(N)最佳。 在表示大O时，低阶项一般可以忽略，常数项也可以弃掉。 例如：T(N)=N/1.5+3T(N) = N/1.5 + 3T(N)=N/1.5+3，这是一个线性函数，系数与常数项可以省略，T(N)=O(N)T(N)=O(N)T(N)=O(N)， 1.4 增长率的比较 通过计算极限limN→∞(f(N)/g(N))lim_{N \\rightarrow \\infty} (f(N)/g(N))limN→∞​(f(N)/g(N))来确定两个函数f(N)与g(N)的相对增长率，必要时可使用洛必达法则 极限是0：意味着f(N)=O(g(N))f(N) = O(g(N))f(N)=O(g(N))。 极限是c(常数)≠0c(常数)\\ne0c(常数)​=0，意味着f(N)=Θ(g(N))f(N) = \\Theta(g(N))f(N)=Θ(g(N)) 极限是∞\\infty∞：意味着g(N)=O(f(N))g(N)=O(f(N))g(N)=O(f(N)) 极限摆动：二者无关(本书中不会出现) 洛必达法则：若limN→∞f(N)=∞lim_{N \\rightarrow \\infty} f(N) = \\inftylimN→∞​f(N)=∞且limN→∞g(N)=∞lim_{N \\rightarrow \\infty} g(N)= \\inftylimN→∞​g(N)=∞，则limN→∞f(N)/g(N)=limN→∞f′(N)/g′(N)lim_{N \\rightarrow \\infty} f(N)/g(N) = lim_{N \\rightarrow \\infty} f&#x27;(N)/g&#x27;(N)limN→∞​f(N)/g(N)=limN→∞​f′(N)/g′(N)。 2. 要分析的问题 运行时间，一般分析最坏的情况。 运行空间：现代计算机而言，空间一般可以不考虑 3. 运行时间计算 计算大O的运行时间，大O是一个上界。分析的结果为程序在一定时间范围内能够终止运行提供了保证。程序可能提前结束，但绝不可能错后。 3.2 一般法则 法则1：for循环 一个for循环的的运行时间至多是该for循环内部语句的运行时间乘以迭代次数。 法则2：嵌套for循环 一组嵌套for循环内部的一条语句运行的总时间，为该语句运行时间乘以该组所有for循环的大小的乘积。 如上：每一个for循环的时间复杂度都是O(N)O(N)O(N)，两个嵌套则为：O(N2)O(N^2)O(N2)。 法则3：顺序语句 将各个语句的运行时间求和即可。其中最大值就是所得的运行时间。如下程序，首先是花费O(N)O(N)O(N)，接着是O(N2)O(N^2)O(N2)，因此总量也是O(N2)O(N^2)O(N2)。 法则4：if/else语句 一个if/else语句的运行时间从不超过判断的运行时间再加上S1和S2中运行时间长者的总运行时间。 3.3 其他情形 显然，分析的策略是从内部向外开展，如果有方法调用，那么首先需要分析这些方法调用。如果有递归过程，有以下几种可能。 实际是for循环的递归：如下，分析很简单，本质上就是一个O(N)的复杂度。 普通正常的递归：实际上正常使用的递归，转换成一个循环结构是非常困难的。如下程序，它递归的使用效率非常低。 该程序的效率实际上非常低。令T(N)T(N)T(N)为调用函数fib(n)的运行时间。 T(N)=fib(n)T(N) = fib(n)T(N)=fib(n) 分析： 如果N=0或N=1，则在第2行即可执行完毕，则可以说T(0)=T(1) =1。 若N&gt;2，则执行该方法的时间是第2行的常数工作加上第5行的工作，第5行由一次加法和两次方法调用组成。 方法调用必须使用他们自己来分析他们，第一次方法调用是fib(n-1),按照T的定义(T(N)=fib(n)T(N) = fib(n)T(N)=fib(n))，它需要T(N-1)个时间单元。类似，第二次方法调用需要T(N-2)个时间单元。 此时总的时间需求为T(N-1) + T(N-2) + 2，其中2指第二行的工作加上第五行的加法，于是对于N≥2N \\ge 2N≥2，有下列运行时间公式。 T(N)=T(N−1)+T(N−2)+2T(N) = T(N-1) + T(N-2) + 2 T(N)=T(N−1)+T(N−2)+2 但是fib(N)=fib(N−1)+fib(N−2)fib(N) = fib(N-1) + fib(N-2)fib(N)=fib(N−1)+fib(N−2) (由程序的递归条件可以确定)，因此由归纳法容易证明，T(N)≥fib(N)T(N) \\ge fib(N)T(N)≥fib(N) 。在1.2.5节证明过fib(N)&lt;(5/3)Nfib(N) &lt; (5/3)^Nfib(N)&lt;(5/3)N (斐波那契数列)，类似,可以证明fib(N)≥(3/2)NN&gt;4fib(N) \\ge (3/2)^N \\quad N&gt;4fib(N)≥(3/2)NN&gt;4；从而证明这个的运行时间以指数速度增长。 该递归耗时长的原因是违背了递归的第四条主要规则合成效益法则。因为在fib(n)=fib(n−1)+fib(n−2)fib(n) = fib(n-1) + fib(n-2)fib(n)=fib(n−1)+fib(n−2)已经计算一次fib(n−2)fib(n-2)fib(n−2)了，fib(n−1)fib(n-1)fib(n−1)又要计算一次。违背了格言&quot;计算任何事情不要超过一次&quot;。 3.4 最大子序列和问题的求解、 子序列之和：给定一个数组，例如[-1,-2,5-3,8,-1]，则最大子序列之和为10 ：5+(-3)+8 子序列：原数组中连续的数组成新的数组 叙述四个算法求解提出的最大子序列和问题。 3.4.1 算法一 如下算法穷举所有的可能。本算法并不计算实际的子序列，实际的计算还要添加一些额外的代码。 该算法的三个嵌套for循环都是O(N),所以最终的时间复杂度为O(N3)O(N^3)O(N3)。忽略常数与低阶项。 精确分析由 ∑i=0N−1∑j=iN−1∑k=ij1\\sum_{i=0}^{N-1} \\sum_{j=i}^{N-1} \\sum_{k=i}^j 1∑i=0N−1​∑j=iN−1​∑k=ij​1 得到。该&quot;和&quot;指出程序被执行多少次被执行。从内向外求值。特别地，将用到前N个整数求和与前N个平方数的和公式。 首先有 ∑k=ij1=j−i+1(j−i+1个1相加)\\sum _{k=i}^j 1 = j-i+1 \\quad (j-i+1个1相加) k=i∑j​1=j−i+1(j−i+1个1相加) 得到 ∑j=iN−1(j−i+1)=(N−i+1)(N−i)2(带入可得从1+2+3...+N−i)\\sum _{j=i} ^{N-1} (j-i+1) = \\frac{(N-i+1)(N-i)}{2} \\quad (带入可得从1+2+3...+N-i) j=i∑N−1​(j−i+1)=2(N−i+1)(N−i)​(带入可得从1+2+3...+N−i) 还有 第一行理解：令i=i-1，求和下标 i-1=0-&gt;i=1，上标 i-1=N-1-&gt;i=N。 ∑i=0N−1(N−i+1)(N−i)2=∑i=1N(N−i+1)(N−i+2)2=12∑i=1Ni2−(N+32)+12(N2+3N+2)∑i=1N1=12N(N+1)(2N+1)6−(N+32)N(N+1)2+N2+3N+22N=N3+3N2+2N6\\begin{aligned} \\sum _{i=0} ^{N-1} {\\frac{(N-i+1)(N-i)}{2}} &amp;= \\sum_{i=1}^N \\frac{(N-i+1)(N-i+2)}{2} \\\\ &amp;= \\frac{1}{2} \\sum_{i=1}^N i^2-(N+\\frac{3}{2}) + \\frac{1}{2}(N^2+3N+2)\\sum_{i=1}^N 1 \\\\ &amp;= \\frac{1}{2}\\frac{N(N+1)(2N+1)}{6}-(N+\\frac{3}{2})\\frac{N(N+1)}{2}+\\frac{N^2+3N+2}{2}N\\\\ &amp;= \\frac{N^3+3N^2+2N}{6} \\end{aligned}i=0∑N−1​2(N−i+1)(N−i)​​=i=1∑N​2(N−i+1)(N−i+2)​=21​i=1∑N​i2−(N+23​)+21​(N2+3N+2)i=1∑N​1=21​6N(N+1)(2N+1)​−(N+23​)2N(N+1)​+2N2+3N+2​N=6N3+3N2+2N​​ 3.4.2 算法二 如下算法具有O(N2)O(N^2)O(N2)的复杂度。 该算法的区别在于，发现不需要使用确定起始位置，只需要求和子序列的起始位置 3.4.3 算法三 如下递归算法具有O(NlogN)O(NlogN)O(NlogN)的复杂度。 1.递归的正确性分析： 该算法采用递归的分治思想，将数组一分为二去计算，因为最大子序列只可能在三处地方出现：二分后的左半部分，二分后的右半部分，二分后的左半与右半的连接部分。 对于第三种情况，可以将前半部分的最大和(从center–)加上后半部分的最大和()从center++得到。 最后比较这三个最大值，即可得到真正的最大值。 3.4.4 算法四 如下递归算法具有O(N)O(N)O(N)的复杂度。 1.算法的正确性分析： j代表当前序列的终点，如果a[i]到a[j]的和是负的，那么可以将i推进到j+1， 令下标：0&lt;i&lt;j，如果thisSum的0到i的和&gt;0，那么，thisSum = a[0] + …+a[i]，如果thisSum为0，则说明，从a[i]开始的子序列不是最优解了。因为如果存在一个最大值从a[i]开始，或包含a[i]，由于thisSum为负，a若[i+k]为正，则继续从a[i+k]一定更优。将thisSum置为0，则之后的最大值从a[i+1]开始，算的值再与maxSum比较，从而得到真正的最大值。 2.联机算法： 在任意时刻，只需要对操作的数据读入一次，一旦a[i]被读入并处理，它不在需要被记忆。在任意时刻，算法都能对已经读入的数据给出对应的子序列的正确问题答案。而且仅需要常量空间并以线性时间运行。 3.5 运行时间的对数 一般法则：如果一个算法用O(1)的时间把问题削减为其一部分(通常为1/2)，那么该算法就是O(logN)。 如果一个算法使用常数的时间，将问题复杂度减少一个常数量，那么为O(N) 3.5.1折半查找 折半查找(binary search)：给定一个整数X和一组已经在内存中且已经排好序的整数数组A0,A1,...,An−1A_0,A_1,...,A_{n-1}A0​,A1​,...,An−1​,求有下标i使,求有下标i使,求有下标i使Ai=XA_i=XAi​=X,如果不存在则返回 i = null。 由于该数组已经排序好，因此采用折半查找： 先查找数组居中的元素，如果等于X，则找到。如果比X小，说明结果在居中数组的右边。比X大则说明在居中数组的左边。循环时间最多为log(N−1)+2log(N-1) + 2log(N−1)+2 3.5.2欧几里得算法(辗转相除法) 计算两个数的最大公因数，如gcd(50, 15) = 5 欧几里得算法(辗转相除法)：gcd(a, b) = gcd(b, a%b) a&gt;=b; gcd(a,b)表示a、b的最大公因数 这是一个快速的算法，如下将证明经过两次迭代后，余数最多是之的一半，从而证明迭代次数至多为2O(logN)2O(logN)2O(logN) 定理1：如果M&gt;N，则M mod N &lt; M/2 (注意java中取余取mod的区别) 证明： 情形1：如果N≤M/2N\\le M/2N≤M/2，则由于余数一定小于除数N，故余数≤N≤M/2余数\\le N \\le M/2余数≤N≤M/2。 情形2：如果N&gt;M/2N &gt; M/2N&gt;M/2，且N&lt;MN&lt;MN&lt;M，所以M一定只包含一个N，从而余数=M−1×N余数=M- 1 \\times N余数=M−1×N，而N&gt;M/2N &gt; M/2N&gt;M/2，所以余数&lt; M/2。 由此可知，M经过两次欧几里得算法后，M变成M%N的余数，故需最坏的情况要2logN的复杂度。实际上该算法的平均复杂度需要大量的复杂计算，其平均迭代次数约为(12ln2lnN)/π2+1.47(12 ln2 lnN)/\\pi^2 + 1.47(12ln2lnN)/π2+1.47 幂运算 计算XNX^NXN的明显的算法是使用N-1次乘法自乘，有一种递归算法更好：N≤1N\\le 1N≤1是递归的基准情形。否则，若N为偶数，我们有XN=XN/2⋅XN/2X^N = X^{N/2} \\cdot X^{N/2}XN=XN/2⋅XN/2，如果N是奇数，则有XN=X(N−1)/2⋅X(N−1)/2⋅XX^N = X^{(N-1)/2} \\cdot X^{(N-1)/2} \\cdot XXN=X(N−1)/2⋅X(N−1)/2⋅X，一直递归下去。 "},{"title":"范型与函数对象","date":"2021-04-03T09:49:59.000Z","url":"/2021/04/03/%E8%8C%83%E5%9E%8B%E4%B8%8E%E5%87%BD%E6%95%B0%E5%AF%B9%E8%B1%A1/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第一章1.4与1.5节读书笔记 1. 范型 范型机制：如果对象除去基本类型外，其余的实现方法相同，可以用范型实现来描述。 1.1 使用Object表示范型 Object类是所有类的超类，可以通过Object类实现范型类。 注意，如果需要一个特定的类型使用，则需要强制转为正确的类型。 不能使用基本类型(8大类型)，只有引用类型(类、接口类型、数组类型、枚举类型)与Object相容。(这里测试实际是可以的(Java8)：自动拆装箱) 1.2 包装类型 Java提供了8种基本类型，这8种类型不能与Objecct相容，所以Java提供了对应的包装类。 1.3 使用接口表示范型 只有在使用Object类中已有的方法能够表示所执行的操作时，才能使用Object作为范型类工作。(与代码对象类型无关)。 例如找出Object数组中的最大项，与类型无关，只能实现Comparable接口，重写compareTo方法。 1.5 利用Java范型特性 Java支持范型类与范型方法 1.5.1 简单范型类和接口 在类上使用&lt;范型&gt;，表示一个范型类。如下是前面的MemoryCell类范型版代码。也可以实现范型接口。 1.5.2 自动拆箱/装箱 自动装箱：如果一个基本类型，例如int被传递到一个需要Integer对象的地方，编译器幕后插入对Integer构造方法调用。 自动拆箱：一个包装类型，例如Integer被放到需要int类型的地方，则编译器幕后调用一个intValue方法。 注意：需要指定范型的地方，仍是不可改变的。 1.5.4 带有限制的通配符 为了解决范型的一些问题，Java使用 通配符：?来解决这些问题，如下方法表示范型必须是Shape类或者其子类。 1.5.6 类型界限 例如，想实现如下代码，编译器不能证明在第行对compareTo的调用是合法的。只有在T是Comparable的情况下才能保证compareTo存在。可以使用类型界限解决。在&lt;&gt;内，指定参数必须具有的性质。 错误的代码： 正确代码：&lt;T extends Comparable&lt;? super T&gt;&gt;： 区别：&lt;T extends Comparable&lt;? super T&gt;&gt;：T必须继承Comparable接口或者父类继承了Comparable接口 &lt;T extends Comparable&lt;T&gt;&gt;：T必须继承Comparable接口 T extends决定了传入对象的上限是T(只能是T或子类)，&lt;? super T&gt;决定了下限是T(最少T实现了Comparable) 1.5.7 类型擦除 Java中的范型是伪范型，只在源码中存在，只在源码中有效，有编译检查。一旦编译通过，Java的范型就会被擦除，成为原生类型，称为类型擦除。 1.5.8 范型的限制 由于类型擦除的原因，下面的每一个限制都必须遵守。 基本类型 基本类型不能用作类型参数，如GenericMemoryCell&lt;int&gt;非法，必须使用包装类。 instanceof检测 insatanceof检测和类型转换只对原始类型(此处的GenericMemoryCell)进行。编译通过后，类型会被擦除，如下： 范型类型不能实例化 不能创建范型数组 不能实例化参数化类型数组 2 函数对象 定义一个只有方法而没有数据的类，然后把这个类的对象传递给别的方法，该对象通常叫做函数对象 2.1 简单实现 如下是一个传递Comparator类型的函数对象的实现 "},{"title":"数学知识复习与递归简论","date":"2021-04-02T08:40:16.000Z","url":"/2021/04/02/%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0%E4%B8%8E%E9%80%92%E5%BD%92%E7%AE%80%E8%AE%BA/","tags":[["数据结构与算法","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"categories":[["cs基础","/categories/cs%E5%9F%BA%E7%A1%80/"],["数据结构与算法","/categories/cs%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"]],"content":"《数据结构与算法分析Java语言描述》第一章1.2与1.3节读书笔记 1. 数学知识复习 1.1 指数 XAXB=XA+BX^AX^B=X^{A+B} XAXB=XA+B XAXB=XA−B\\frac{X^A}{X^B}=X^{A-B} XBXA​=XA−B 1.2对数 在计算机科学中，除非特别声明。否则所有对数都是以2为底。 定理1.1： logAB=logCBlogCA;A,B,C&gt;0,A≠1log_AB=\\frac{log_CB}{log_CA}; \\quad A,B,C&gt;0,A\\ne1 logA​B=logC​AlogC​B​;A,B,C&gt;0,A​=1 定理1.2: logAB=logA+logB;A,B&gt;0logAB=logA+logB; \\quad A,B&gt;0 logAB=logA+logB;A,B&gt;0 推导： logA/B=logA−logBlogA/B=logA-logB logA/B=logA−logB log(AB)=BlogAlog(A^B)=BlogA log(AB)=BlogA logX&lt;X对所有的X&gt;0成立logX&lt;X对所有的X&gt;0成立 logX&lt;X对所有的X&gt;0成立 1.3 级数 ∑i=0n2i=2N+1−1\\sum_{i=0}^n2^i=2^{N+1}-1 i=0∑n​2i=2N+1−1 ∑i=0nAi=AN+1−1A−1\\sum_{i=0}^nA^i=\\frac{A^{N+1}-1}{A-1} i=0∑n​Ai=A−1AN+1−1​ 如果0&lt;A&lt;1 则 ∑i=1NAi≤11−A\\sum_{i=1}^N A^i \\le \\frac{1}{1-A} i=1∑N​Ai≤1−A1​ ∑i=1Ni=N(N+1)2≈N22\\sum_{i=1}^N i = \\frac{N(N+1)}{2} \\approx \\frac{N^2}{2} i=1∑N​i=2N(N+1)​≈2N2​ ∑i=1Ni2=N(N+1)(2N+1)6≈N33\\sum_{i=1}^N {i^2} = \\frac{N(N+1)(2N+1)}{6} \\approx \\frac{N^3}{3} i=1∑N​i2=6N(N+1)(2N+1)​≈3N3​ ∑i=1Nik≈Nk+1∣k+1∣k≠−1\\sum_{i=1}^N {i^k} \\approx \\frac{N^{k+1}}{|k+1|} \\quad k \\neq -1 i=1∑N​ik≈∣k+1∣Nk+1​k​=−1 当k=-1时，上面的公式不成立，需要下面的公式。HNH_NHN​为调和 和，下面近似式的误差γ≈0.57721566\\gamma \\approx 0.57721566γ≈0.57721566，称为欧拉常数 HN=∑i=1N1i≈logeNH_N = \\sum_{i=1}^N \\frac{1}{i} \\approx log_e^N HN​=i=1∑N​i1​≈logeN​ 以下一般代数运算： ∑i=1Nf(N)=Nf(N)\\sum _{i=1}^N f(N) = Nf(N) i=1∑N​f(N)=Nf(N) ∑i=n0Nf(i)=∑i=1Nf(i)−∑i=1n0−1f(i)\\sum _{i=n_0}^N f(i) = \\sum _{i=1}^Nf(i) - \\sum _{i=1}^{n_0-1}f(i) i=n0​∑N​f(i)=i=1∑N​f(i)−i=1∑n0​−1​f(i) 1.4 模运算 如果A-B整除以N，那么A与B模N的余数是相同的。记作A≡BA \\equiv BA≡B(mod N)。 1.5 证明方法 1. 归纳证明法 第一步证明基准情形，确定定理对最基准的值的正确性。 进行归纳假设，假设定理对直到有限数 k 的的所有情况都是成立的。 依据这个假设证明定理对下一个值(k+1)成立。 1.1证明演示 证明斐波那契数列，F0=1F_0=1F0​=1, F1=1F_1=1F1​=1, F2=2F_2=2F2​=2, F3=3F_3=3F3​=3, F4=5F_4=5F4​=5, …, ,Fi=Fi−1+Fi−2F_i=F_{i-1}+F_{i-2}Fi​=Fi−1​+Fi−2​, 满足对i≥1i\\ge1i≥1，有Fi&lt;(5/3)iF_i &lt; (5/3)^iFi​&lt;(5/3)i。 证明： 基准情形：F1=1&lt;53F_1=1&lt; {\\frac{5}{3}}F1​=1&lt;35​，F2=2&lt;259F_2 = 2&lt; {\\frac{25}{9}}F2​=2&lt;925​ 归纳假设：假设定理对于i=1，2，…，k成立，则有Fk&lt;(5/3)kF_k &lt; (5/3)^kFk​&lt;(5/3)k 证明k+1成立： 由定义有： Fk+1=Fk+Fk−1F_{k+1} = F_k + F_{k-1}Fk+1​=Fk​+Fk−1​ 则有：Fk+1&lt;(5/3)k+(5/3)k−1=(3/5)(5/3)k+1+(3/5)2(5/3)k+1=(3/5+9/25)(5/3)k+1&lt;(5/3)k+1F_{k+1} &lt; (5/3)^k + (5/3)^{k-1} =(3/5)(5/3)^{k+1} + {(3/5)^2}{(5/3)^{k+1}} = (3/5 + 9/25){(5/3)^{k+1}} &lt; (5/3)^{k+1}Fk+1​&lt;(5/3)k+(5/3)k−1=(3/5)(5/3)k+1+(3/5)2(5/3)k+1=(3/5+9/25)(5/3)k+1&lt;(5/3)k+1 2. 反证法 假设某个定理不成立。 证明该假设导致某个已知的性质不成立，证明原假设是错误的(定理成立)。 2.1 证明演示： 证明存在无穷多个素数。 证明： 1.假设定理不成立：假设不存在无穷多个素数。 2.推导某个已知性质不成立： 由1的假设有最大素数PkP_kPk​，令P1,P2,...,PkP_1,P_2,...,P_kP1​,P2​,...,Pk​依序排列。 考虑有 ： N=P1P2P3...Pk+1N=P_1 P_2 P_3...P_k +1N=P1​P2​P3​...Pk​+1 显然，N&gt;PkN&gt;P_kN&gt;Pk​，根据假设(PkP_kPk​为最大素数，则N比不为素数)。但是N不能整除以P1,P2,...,PkP_1,P_2,...,P_kP1​,P2​,...,Pk​。产生矛盾，因为每一个整数要么是素数，要么是素数的乘积。 因此PkP_kPk​是最大的素数假设不成立，意味定理成立。 2. 递归简论 2.1 递归四条基本法则： 基准情形：必须包含某些基准情形，无需递归就能解出。(程序出栈条件) 不断推进：每一次递归，必须朝着基准情形推进 设计法则：假设所有递归调用都能运行 合成效益法则：在求解一个问题的同一实例时，切勿在不同的递归调用中做重复性的工作。(在计算F(n-1)时同时调用了F(n-2)，而同时原式也需要调用一次F(n-2)，重复) "},{"title":"HotSpot的细节实现","date":"2021-03-30T07:51:09.000Z","url":"/2021/03/30/HotSpot%E7%9A%84%E7%BB%86%E8%8A%82%E5%AE%9E%E7%8E%B0/","tags":[["Jvm","/tags/Jvm/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"HotSpot的细节实现 (读书笔记) 1. 根节点(GC Roots)枚举 枚举出所有GC Roots根节点 可以作为GC Roots的节点主要有：全局性的引用与上下文执行，详见JVM垃圾回收的可达性分析小节。目前，所有收集器进行根节点(GC Roots)枚举必须STW。现在可达性分析算法耗时查找引用链可以与用户线程一起并发。 目前的Java虚拟机使用准确式垃圾回收集，所以当用户线程1后，并不需要检查完所有上下文和全局引用位置，虚拟机应当直接得到哪些地方存放对象引用。HotSpot使用OopMap的数据结构。(并不需要真的全部从方法区等GC Roots开始查找)。 2. 安全点(SafePoint) 在&quot;特定的位置&quot;记录修改引用关系的指令 在程序运行期间很多指令都是有可能修改引用关系的，即要修改OopMap，如果对每一条指令都生成OopMap，将会需要大量的空间存储数据结构。因此设置了SafePoint去强制用户程序执行到SafePoint暂停开始处理OopMap 并GC。 安全点位置的选取基本上是以“是否具有让程序长时间执行的特征”为标准进行选定的。(“长时间执行”的最明显特征就是指令序列的复用，与指令长短无关。例如方法调用、循环跳转、异常跳转 等都属于指令序列复用，所以只有具有这些功能的指令才会产生安全点)。 需要考虑所有线程都在安全点停顿：抢先式中断、主动式中断。 抢先式中断：GC时先中断所有用户线程，如果发现有线程没有到达安全点，恢复执行，直到所有线程到安全点(目前几乎不用) 主动式中断：GC时，不直接对线程操作，记录一个标志，各线程不断轮询这个标志(标志与安全点重合)，一旦发现中断标志为真时，在自己最近的中断点主动中断挂起。 HotSpot为了提高轮询的效率，使用内存保护陷阱方式，将轮询操作精简至汇编指令。 内存保护陷阱：需要暂停用户线程，把xx内存页设置不可读，执行test指令会产生一个自陷异常信号，被预先注册的异常挂起等待。 3. 安全区域 指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点。 长时间不执行的某段代码，该线程无法响应虚拟机的中断请求，必须引入安全区域(Safe Region)解决。 当用户线程执行到安全区域里面的代码时，首先标识自己进入安全区域。垃圾收集时，不需要处理这些安全区域的线程。当线程离开安全区域，要检查虚拟机是否已经完成根节点枚举。如果完成，线程正常继续执行，否则一直等待，直到收到可以离开安全区域的信号。 4. 记忆集与卡表 4.1 记忆集 记忆集：记录从非收集区域指向收集区域的指针集合的抽象数据结构。 记忆集是为了解决对象跨代引用的问题，新生代建立的数据结构，避免把老年代加入GC Roots扫描范围。如果不考虑效率和成本，最简单的实现可以用非收集区域中所有跨代引用的对象数组实现。垃圾收集器不需要这么完整的记录精度。 字长精度：每个记录精确到一个机器字长(处理器寻址位，如32位、64位)，该字包含跨代指针。 对象精度：每个记录精确到一个对象，该对象字段含有一个跨代指针。 卡精度：每个记录精确到一块内存区域，该区域含有跨代指针。 4.2 卡表 上面的卡精度就是用卡表实现的记忆集，卡表就是记忆集的一种具体体现，它定义了记忆集的记录精度、与堆内存映射的关系(卡表与记忆集类比HashMap与Map的关系记忆) 卡表的最简单的形式可以只是一个字节数组，HotSpot默认卡表逻辑 字节数组CARD_TABLE的每一个元素都对应着其表示区域中一块大小的内存块，这个内存块被称作&quot;卡页&quot;(Card Page)。一般卡页都是2n2^n2n字节数。如上代码，HotSpot虚拟机使用的卡页是292^929，即512字节(地址右移9位，地址除以292^929)。 如果卡表标识内存区域的起始地址是0x0000的话，数组CARD_TABLE的第0、1、2号元素，分别对应了 地址范围为0x0000～0x01FF、0x0200～0x03FF、0x0400～0x05FF的卡页内存块。 一个卡页的内存中通常包含不止一个对象，只要卡页内有一个（或更多）对象的字段存在着跨代 指针，那就将对应卡表的数组元素的值标识为1，称为这个元素变脏（Dirty），没有则标识为0。在垃 圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把它们加入GC Roots中一并扫描。 5. 写屏障 使用记忆集缩减GC Roots扫描范围后，还需要解决卡表的元素维护问题，例如它们何时变脏、谁把它们变脏。 何时变脏：有其他分代区域对象引用本区域对象时，卡表变脏。 谁操作：写屏障(Writte Barrier)。 写屏障：看作虚拟机层面对&quot;引用类型字段赋值&quot;这个动作的AOP切面，在引用对象赋值时会产生一个环形通知，供程序执行额外动作。直至G1收集器出现之前，其他收集器都只用到了写后屏障。 开启写屏障会导致每次引用更新产生额的开销。 卡表在高并发场景下面临&quot;伪共享&quot;问题：现代处理器的缓存系统是以缓存行为单位存储的，当多线程修改互相独立的变量时，如果这些变量恰好位于同一个缓存行，会彼此影响(写回、无效化、同步)，导致性能降低。 如果处理器的缓存行大小为64字节，由于一个卡表元素占1个字节，64个卡表元素将共享同一个缓存行，这64个卡表元素对应的卡页总内存为32KB(64*512字节)。如果不同线程更新的对象正好处于32KB的内存区域，导致更新卡表时正好写入同一个缓存而影响性能。 避免伪共享问题：先检查卡表标记，只有当卡表元素未被标记时才将其变脏。在JDK 7之后，HotSpot虚拟机增加了一个新的参数-XX：+UseCondCardMark，用来决定是否开启 卡表更新的条件判断。开启会增加一次额外判断的开销，但能够避免伪共享问题。 6. 并发的可达性分析 可达性分析理论上要求全部过程都基于一个能保证一致性的快照中才能进行分析。意味着要全程STW。 在根节点枚举中，由于OopsMap的存在，停顿相对固定，不与堆相关。但是GC Roots往下遍历耗时依旧与Java堆成正比例关系。 为生么必须保证一致快照才能遍历？ 6.1 三色标记： 白色：对象尚未被垃圾收集器访问过。如果在分析结束阶段，仍是白色，则不可达。 黑色：对象已经被垃圾收集器访问过，且该对象的所有引用都访问过，黑色对象不可能直接指向白色对象。 灰色：对象已经被垃圾收集器访问过，但对象上至少还有一个引用每一被扫描过。 5.2 三色标记的过程： 首先GCRots被染成灰色，从GCRoots向下遍历。将GCRoots指向白色的对象在染成灰色，在该GCRoots遍历完直接指向的对象后，该GCRoots染成黑色。再从被染灰色的对象向下遍历，重复上面的过程，遍历完成后。剩余的白色对象被判断为垃圾。 5.3 并发三色标记的问题： 如果用户收集线程与GC线程并发工作， 可能会出现两种问题。 将原本消亡的对象标记为存活： GC线程将某对象标记为黑色，这时用户线程将该对象的引用去除，导致该对象实际应该消亡，但是被标记为黑色，导致存活。(可以忍受，称为浮动垃圾)。(独立的非GCRoots的黑色对象) 将原本存活的对象标记为垃圾： 赋值器插入了一条或多条从黑色对象到白色对象的新引用。(添加黑色指向白色) 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。(删除灰色指向白色的链接) 由于GC不会再从黑色对象开始遍历，所以该白色对象不会再被标记。标记完成后，该对象被误判为垃圾。(不可忍受)，需要两个条件同时满足。 5.4 三色并发标记问题的解决 由于必须同时满足两个条件，只需破坏其中一个即可。 增量更新与原始快照。 5.4.1 增量更新 增量更新破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，将这个新的插入记录下来，等并发扫描结束后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。(一旦黑色对象指向指向白色对象，将黑色对象转变为灰色)。 5.4.2 原始快照 原始快照破坏第二个条件，当灰色对象删除指向白色对象的引用时，将这个要删除的引用记录下来，在并发扫描结束后，将这些记录过的灰色对象为根，从新扫描一次。(无论引用关系删除与否，按刚开始扫描的那一刻的对象快照搜索)。 5.5 三色标记补充 以上对引用关系的插入或删除，都是通过写屏障实现的。例如CMS是基于增量更新做并发标记，G1、Shenandoah使用原始快照。 参考 《深入理解Java虚拟机 JVM高级特性与最佳实践》第二部分第三章 "},{"title":"hexo编辑相关","date":"2021-03-22T08:00:09.000Z","url":"/2021/03/22/hexo%E7%BC%96%E8%BE%91%E7%9B%B8%E5%85%B3/","categories":[["站点相关","/categories/%E7%AB%99%E7%82%B9%E7%9B%B8%E5%85%B3/"],["博客相关","/categories/%E7%AB%99%E7%82%B9%E7%9B%B8%E5%85%B3/%E5%8D%9A%E5%AE%A2%E7%9B%B8%E5%85%B3/"]],"content":"记录hexo常用操作 1. hexo首行缩进： 一个代表一个汉字字符 2.hexo文章跳转其他文章 你好世界 3. 添加数学公式 数学公式 博客2 (某CSDN博客) 空格 ：a,b a;b a\\ b a\\quad b 4. 空行 5. 字自定义 6.hexo新建草稿 7.hexo将草稿发布 8.katle渲染引擎todo问题 换渲染引擎后todoList渲染出现问题，使用html语法 9. 添加图片 添加文献引用 "},{"title":"JVM垃圾回收","date":"2021-03-22T01:39:32.000Z","url":"/2021/03/22/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","tags":[["Jvm","/tags/Jvm/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"JVM的GC读书笔记 STW：Stop The World，GC时暂停用户的线程。 STAB：Snapshot At The Beginning，原始快照(保留开始时的对象图)。用于解决并发扫描时对象消失的问题。 TAMS：Top at Mark Start，G1为每个Region设计的两个名为TAMS的指针，并发回收时新分配的对象地址都必须要在这两个指针位置以上。 1. 内存分配与回收策略 Java堆是垃圾回收器管理的主要区域，因此也被称为GC堆。现代收集器基本采用分代垃圾回收算法。所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间、老生代等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 总结：Eden区：标记-复制； Survivor区：标记-复制； 老生代：标记整理。 大部分情况下，对象首先在Eden区分配，在一次新生代GC后，如果对象还活着，则会进入S0或者S1，并且对象的年龄还会加1(Eden-&gt;Survivor区后对象的初始年龄变为1)，当它的年龄增加到一定的程度，就会晋升到老年代中，年龄阈值可以通过参数-XX:MaxTenuringThreshold设置。 动态年龄计算：“Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值”。 对象首先在Eden区诞生，如果Eden区满了，执行Minor GC，将Eden区和Survivor From区存活对象复制到Survivor To区，清除Eden区和Survivor From区。 Eden区相当于标记-复制算法(标记后复制到Survivor To区，清除Eden区)。Survivor From/To区是标记-复制算法，Survivor区一分为二，From区对象经历一次标记后，复制到To区，清除From区。 1.1 HotSpot虚拟机GC 针对HotSpot VM的实现，它里面的GC准确的分类只有两大种： 部分GC(Partial GC): 新生代收集(Minor GC / Young GC) ：只对新生代进行垃圾收集 老年代GC(Major GC / Old GC) ：只对老年代进行垃圾收集。(Major GC在有的语境下= Full GC，注意问清楚提问者意图) 混合收集(Mixed GC)：对整个新生代和部分老年代进行垃圾收集 整堆收集(Full GC)：收集整个Java堆和方法区 2. 对象已死？ java堆是垃圾回收的主要区域，因此也成为GC堆。在进行回收前，需要判断对象是否死亡。算法：引用计数法、可达性分析算法。 2.1 引用计数法 给对象添加一个引用计数器，每当有一个对象引用它，计数器加一；当引用失效时，计数器减一；任何时刻计数器为零的对象就是不可能在被使用的。 这个方法原理简单，效率也高。但是，在主流Java虚拟机没有使用引用计数法来管理内存，主要原因是很难解决对象的相互循环引用的问题。(相互循环引用：对象A与对象B相互引用，除此之外再无其他引用，实际上这两个对象已经不能再被访问，但是他们相互引用着对方，导致他们的引用计数不为零，引用计数算法无法回收他们)。 2.2 可达性分析算法 基本思路是通过一系列称为&quot;GC Roots&quot;的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索通过的路径称为&quot;引用链&quot;(Reference Chain)，如果某个对象到GC Roots没有任何引用链相连，则该对象是不可用的。 Java中，可以作为GC Roots的对象是： 虚拟机栈(栈帧中的本地变量表)中引用的对象。 本地方法栈(Native方法)中引用的对象 在方法区中的类静态属性引用的对象 在方法区中常量引用的对象 所有被同步锁持有的对象 2.3 再谈引用 无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否引用链可达，判定对象是否存活都和“引用”离不开关系。希望描述一些对象：当内存空间足够时，能够保留在内存之中，如果内存空间在GC后仍然紧张，就可以抛弃这些对象。 在JDK1.2之后，Java对引用的概念进行了扩充，将引用分为强引用（Strongly Re-ference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4种，这4种引用强 度依次逐渐减弱。 强引用：指程序代码之中最普遍存在的引用赋值，类似&quot;Object obj = new Object()&quot;，(栈上的对象指向堆中的对象)这种引用关系，只要强引用关系还在，GC回收器永远不会回收被强引用的对象。(宁愿抛出OOM错误) 软引用：指一些有用，但非必须的对象。在系统将要发生内存溢出前，会对这些对象进行二次回收，如果这次回收没有足够的内存，才会抛出OOM(Out Of Memory Error)异常。JDK1.2之后提供SoftReference类实现软引用 弱引用：指一些有用，但非必须的对象，但它的强度比软引用更弱。当垃圾收集器开始工作时，无论当前内存是否足够，都会回收被弱引用关联的对象。JDK1.2之后提供了WeakReference类实现弱引用 虚引用：是一种最弱的引用关系，形同虚设，无法通过虚引用获取一个对象实例，任何时候都能被回收。JDK1.2之后提供了PhantomReference类实现虚引用。 为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。 特别注意：在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 2.4 不可达对象并非&quot;非死不可&quot; 即使在可达性分析算法中判定为不可达的对象，也不是&quot;非死不可&quot;的，这时候他处于&quot;缓刑&quot;阶段。 宣判死亡至少要经历两两次标记过程：如果对象在进行可达性分析后发现不可达，那么进行第一次标记，随后筛选一次，如果该对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，那么虚拟机将这两种情况视为&quot;没有必要执行&quot;。(finalize()方法只会执行一次，第二次不会执行(即使覆盖) )。 如果这个对象有必要执行finalize()方法，那么该对象会被放置在一个名为F-Queue的队列中，在之后虚拟经济自动建立一个低优先级的Finalizer线程区执行finalize()方法。 不推荐使用finalize()方法。 2.5 方法区(元空间)的回收 Java虚拟机规范不强制要求是否在虚拟机的方法区(元空间)实现垃圾回收，方法区的垃圾回收&quot;性价比比较低&quot;。 方法区的垃圾回收主要有两部分内容：废弃的常量和不再使用的类型。 判断一个常量是否废弃： 常量池中的方法、字段符号等等如果没有对象引用它，如果这时发生回收且有必要的话，该对象就会被清理出常量池。 判断一个类是否废弃：需要满足下列3个条件(仅说明被允许，不一定必然)： 该类的所有实例都已经被回收(堆中不再有该类与该类的子类的实例) 加载该类的类加载器已经被回收(除非是设计的可替换的类加载器，否则很难达成) 改了对应的java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。 3. 垃圾回收算法 标记清除、标记复制、标记整理、分代垃圾回收。 3.1 标记-清除算法 分为&quot;标记&quot;和&quot;清除&quot;两个阶段：标记出所有不需要回收的对象，标记完成后，统一回收所有未被标记的对象。最基础的算法。其他算法都是对其缺点改进而来。 缺点：效率不稳定、内存空间的碎片化。 3.2 标记-复制算法 半区复制：将可用内存一分为二相等的两块，每次使用其中的一块。当这一块使用完后，将还存活的对象复制到另一块去，然后把使用的空间清理。这样就使每次的内存回收都是对内存区间的一半进行回收。 优点：不会出现碎片化问题，效率高。 缺点：内存只能使用一半 3.3 标记-整理算法 针对老年代存亡的特征，提出了&quot;标记-整理&quot;算法。标记过程同&quot;标记清除&quot;算法，但后续的步骤不是直接对回收对象进行清理，而是让所有存活的对象都向内存空间的一端移动，然后直接清理掉边界以外的内存。 如果移动所有的存活对象，将会是一种极为负重的操作，而且会暂停用户应用程序才能进行，这样的停顿被称为&quot;Stop The World&quot;。 如果不移动，采用标记清除，空间会碎片化。 关注吞吐量的虚拟机采用标记-整理，关注延迟的采用标记-清除。 3.4 分代收集算法 根据弱分代假说与强分代假说，现代垃圾收集器将Java堆至少划分为新生代与老年代两个区域。 根据跨代引用假说：存在互相引用关系的两个对象，是应该倾 向于同时生存或者同时消亡的。只需在新生代上建立一个全局的数据结构（该结构被称 为“记忆集”，Remembered Set） 比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 弱分代假说：绝大多数对象都是朝生夕灭的。 强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡。 跨代引用假说：跨代引用相对于同代引用来说仅占极少数。 4. 经典垃圾收集器 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 jdk8环境下，默认使用 Parallel Scavenge（新生代）+ Parallel Old（老年代）。 现在JVM64位默认使用Server类型 4.1 Serial(串行)收集器 Serial (串行)收集器是最基础的收集器，如其名一样是一个单线程工作的收集器，不仅意味着只会使用一个处理器或一条线程去完成垃圾收集，最重要的是强调它进行垃圾回收时需要暂停其他所有工作线程(“Stop the World”)，直到收集结束。Stop The World对很多应用而言是不可接受的。 新生代采用标记-复制，老生代采用(Serial Old)标记-整理，该收集器应用在新生代 优缺点：简单而高效，额外内存消耗最小，没有线程的交互开销。具有很高的单线程收集效率，Seriall收集器对于运行在Client模式下的虚拟机来说是个不错的选择。 4.2 ParNew(并行)收集器 ParNew收集器实质上是Serial收集器的多线程版，除了同时使用多条线程进行垃圾收集之外，其余的行为(控制参数、收集算法、对象分配规则、回收策略)与Serial收集器完全一致。 新生代采用标记-复制，老生代采用(Serial Old)标记-整理，该收集器应用在新生代 在JDK1.7之前ParNew是许多运行在Server模式下的HotSpot虚拟机的新生代首要选择。除了Serial收集器外(JDK9之前)，目前只有ParNew能与CMS收集器配合工作。 (G1这个面向全堆的垃圾收集器诞生，自JDK9开始，ParNew加CMS不再是官方推荐的服务端模式下的收集器解决方案。官推荐G1，同时：取消了ParNew加 Serial Old以及Serial加CMS这两组收集器组合的支持，意味着ParNew和CMS从此只能互相搭配使用) 并行和并发概念补充： 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上，由于收集器占用一部分资源，此时程序的吞吐量受一定影响。 4.3 Parallel Scavenge(并行JDK8)收集器 JDK8默认新生代收集器，“吞吐量优先收集器”。-XX:+UseParallelGC -XX:-UseParallelOldGC同时启用两个收集器搭配。JDK9时官宣G1替代Parallel Scavenge加Parallel Old组合。 Parallel Scavenge与ParNew非常相似，并行收集的多线程收集器，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间(Stop The World)，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput），高效率的利用CPU。所谓吞吐量就是处理器用于运行用户代码的时间与处理器总消耗时间的比值。 吞吐量=运行用户代码的时间运行用户代码的时间+运行垃圾收集时间吞吐量 = \\frac{运行用户代码的时间}{运行用户代码的时间+运行垃圾收集时间} 吞吐量=运行用户代码的时间+运行垃圾收集时间运行用户代码的时间​ 如果对收集器运作不了解，手工优化困难，可以使用Paralle Scavenge收集器配合自适应调节策略，只需要设置好基本的内存数据(如-Xmx设置最大堆)，然后使用-XX:MaxGCPauseMillis(更关注最大停顿时间)，或者-XX:GCTimeRatio(更关注吞吐量)给虚拟机设置一个优化目标，具体细节由虚拟机去调节。 新生代采用标记-复制，老生代采用(Serial Old)标记-整理，该收集器应用在新生代 官方建议策略 尽量不设置最大堆，选择合适的目标吞吐量 如果可以达到吞吐量目标，但是暂停时间太长，请选择一个暂停时间目标进行折衷（以降低吞吐量为代价） 如果未达到吞吐量目标，请设置尽可能大的堆（小于物理可用内存) 4.4 Serial Old(串行)收集器 Serial 收集器的老年代版本，他是一个单线程的收集器，使用标记-整理算法，主要意义供客户端的HotSpot虚拟机使用。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。 3.5.5 Parallel Old(并行)收集器 -XX:+UseParallelOldGC开启该收集器，老年代并行收集器 Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记整理。JDK6提供，解决了Parallel Scavenge只能与Serial Old使用的尴尬地位，无法与CMS配合使用。至此&quot;吞吐量优先&quot;收集器有了比较名副其实的搭配组合。注重吞吐量或者处理器比较稀缺的场合可以考虑。 3.5.6 CMS(并发)收集器 -XX:+UseConcMarkSweepGC开启CMS，老年代并发收集器， CMS(Concurrent Mark Sweep)收集器以最短停顿时间为目标，互联网网站或者B/S系统的服务端非常适合使用(如果老年代不频繁GC或者内存&lt;6g推荐，JDK9时被官方不推荐，推荐G1)。从名称可以看出CMS收集器基于标记清除算法实现. 整体分为四个步骤： 初始标记：暂停所有其他线程(STW)，记录下与GCRoots相连的对象，速度很快； 并发标记：从GCRoots关联的对象开始遍历整个对象标记，耗时长但不需要STW，因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。(采用增量更新算法解决并发扫描时对象消失的问题) 重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。通常停顿时间比初始标记时间长，远比并发标记时间短。 并发清除：清理删除标记阶段判断已经死亡的对象，不需要移动存活对象，可以与用户线程并发。 可以看到，耗时最长的并发标记和并发清除，垃圾收集器和用户线程可以一起并发执行。 优点：并发收集、低停顿 缺点： 对处理器资源敏感：并发阶段虽不会STW，但是会占用一部分线程。 无法收集浮动垃圾： (浮动垃圾：并发标记/清理阶段，用户线程运行，垃圾对象产生，CMS这次GC无法处理，只能下次处理)。 由于无法收集浮动垃圾可能出现：“Concurrent Mode Failure&quot;失败而导致STW的Full GC产生。 JDk1.6时，CMS收集器的启动阈值老年代使用空间默认提升至92%，要是CMS运行期间，预留的内存无法满足分配对象，会出现一次&quot;并发失败”，导致冻结用户线程(STW)，临时启用Serial Old收集器。请根据实际需要设置参数-XX: CMSInitiatingOccupancyFraction参数(启用阈值) 标记清除，产生空间碎片： -XX: +UseCMS-CompactAtFullCollection默认开启，JDK9废弃，CMS收集器不得不FullGC时开启合并整理(STW) -XX: CMSFullGCsBeforeCompactionJDK9废弃，表示CMS执行n次FullGC后，整理，默认为0：每次FullGC会碎片整理。 3.5.7 G1收集器 G1(Garbage First)收集器主要是面向服务端的收集器，开创局部收集思路和基于Region的内存布局形式，主要针对配备多颗处理器及大容量内存($\\geq$6g)的机器。 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。G1的出现(JDK7正式出现)导致CMS被官方声明为不推荐的收集器，同时用来取代Parallel Scavenge加Parallel Old组合。G1是一个面向整堆(新生代+老年代)的收集器。 G1虽然仍是遵循分代收集理论设计的，但是：G1把连续的Java堆划分为多个相等的独立区域(Region)，每个Region都可以根据需要扮演Eden空间、Survivor空间或者老年代，G1能够对扮演不同角色的Region采用不同的策略去处理。 Region种有一类特殊的Humongous区域，专门存储大对象(大小超过一个Region容量的一半)，每个Region可以通过参数-XX:G1HeapRegionSize设置，取值1MB~32MB，且为2n2^n2n，对于超过整个Region的大对象，会被存放在N个连续的Humongous Region中，G1大多数把Humongous Region作为老年代的一部分看待。 1. 布局模型： 2. G1收集器的特点： 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。 3. G1收集器的运作过程： 初始标记(Initial Marking)：仅标记GC Roots能直接关联的对象，需要修改TAMS指针，需要STW，但耗时短，且是借用Minor GC的时候同步完成，所以没有额外停顿。 并发标记(Concurrent Marking)：从GC Roots开始进行可达性分析，递归扫描整个堆，找到要回收的对象，耗时长，但可与用户线程并发执行，重新处理SATB记录下并发时有引用变动的对象。(采用SATB解决并发扫描时对象消失的问题) 最终标记(Final Marking)：对用户线程做一个短暂的暂停，用于处理并发标记阶段结束后仍遗留的STAB记录。 筛选回收(Live Data Counting and Evacuation)：对各个Region的回收价值和成本排序，制定回收计划，自由选择任意多个Region构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧 Region的全部空间，对象移动，需要STW。多条收集器线程并行执行。 G1除了并发标记阶段，其余阶段都需要STW，符合官方设定的目标：在延迟可控的情况下获得尽可能高的吞吐 量。 4. G1常用参数 G1的参数 作用 -XX:+UseG1GC 使用 G1 垃圾收集器 -XX:MaxGCPauseMillis=200 设置期望达到的最大GC停顿时间指标（JVM会尽力实现，但不保证达到） -XX:InitiatingHeapOccupancyPercent=45 启动并发GC周期时的堆内存占用百分比. G1之类的垃圾收集器用它来触发并发GC周期,基于整个堆的使用率,而不只是某一代内存的使用比值. 为 0 则表示”一直执行GC循环”. 默认占用率是整个 Java 堆的 45% -XX:NewRatio=n 新生代与老生代(new/old generation)的大小比例(Ratio). 默认值为 2. -XX:SurvivorRatio=n eden/survivor 空间大小的比例(Ratio). 默认值为 8. -XX:MaxTenuringThreshold=n 提升年老代的最大临界值(tenuring threshold). 默认值为 15. -XX:ParallelGCThreads=n 设置垃圾收集器在并行阶段使用的线程数,默认值随JVM运行的平台不同而不同.最多为8 -XX:ConcGCThreads=n 并发垃圾收集器使用的线程数量. 默认值随JVM运行的平台不同而不同. -XX:G1HeapRegionSize=n 使用G1时Java堆会被分为大小统一的的区(region)。此参数可以指定每个heap区的大小. 默认值将根据 heap size 算出最优解. 最小值为 1Mb, 最大值为 32Mb. 5. G1收集器与CMS收集器的比较： 由于G1与CMS都关注停顿时间的控制，因此它门经常会被拿来比较。 CMS G1 JDk 1.6以上 1.7以上 回收区域 老年代 整堆 回收算法 标记清除 整体来看“标记-整理”；局部来看“标记-复制” 内存布局 传统连续的新生代和老年代 分成Region区，每个区域根据需要扮演新生代与老年代 指定最大停顿时间 否 是 按收益动态收集 否 是 浮动垃圾 是 否 内存碎片 是 否(最终标记STW，不会产生) 卡表(处理跨代指针) 卡表简单 复杂，每个Region都有，可能需要更多空间 Full GC 内存回收达不到分配Full GC 内存回收达不到分配Full GC 6. G1解决的一些问题 跨Region引用对象解决：使用记忆集，每个Region维护一份，记忆集记录别的Region指向自己的指针，标记指针在哪些卡也页范围。本质上是哈希表，这种双向卡表：我指向谁，同时有谁指向我。 并发标记阶段收集线程与用户线程互不干扰： 保证用户线程改变对象引用关系时，不会打破原本的对象图结构，导致标记结果出错。CMS采用增量更新算法，而G1采用原始快照(SATB)。 回收过程中新对象创建，每个Region两个TAMS指针，把Region一部分空间划分用于并发回收的对象分配，必须分配到TAMS指针位置上，G1默认不回收他们。 停顿预测模型：以衰减均值（Decaying Average）为理论基础来实现。通过这些信息预测现在开始回收，由哪些Region组成回收集才可以在不超过期望停顿时间的约束下获得最高的收益。 5. 低延迟垃圾收集器 垃圾收集器的三项指标：内存占用、吞吐量、延迟。优秀的收集器通常最多能实现其中的两项。目前更关注：延迟。内存变大的发展，完整的GC会导致延迟更高。出现了低延迟垃圾收集器。 Compact：整理； Concuurent=Conc：并发； partial： 5.1 Shenandoah收集器 ToDo 5.2 ZGC 可参考 新一代垃圾回收器ZGC的探索与实践 在对吞吐量影响不大的情况，实现对任意堆内存大小垃圾收集停顿时间限制在10毫秒内。 ZGC可以降低延迟(在低延迟：TP999&lt;200ms收益较大)。 但会带来吞吐量下降情况(ZGC单代垃圾回收，每次回收处理对象更多，更耗CPU资源；ZGC使用读屏障，需要额外消耗计算资源)。 JDK11(Linux)开始。JDK15(Windows)开始。 1. 特点： 基于Region(官方：page/ZPage)内存布局，染色指针和读屏障解决转移过程中对象的访问问题，同时实现了可并发的标记-整理算法，以低延迟位首要目标。 2. 内存布局 ZGC基于Region堆内存布局，但ZGC的Region具有动态性：动态创建与销毁、动态区域容量大小。 小型Region(Small Region)：容量固定2MB，放置小于256KB对象。 中型Region(Small Region)：固定32MB，放置256KB≤\\leq≤n$\\leq$4MB对象。 大型Region(Large Region)：容量不固定，但必须为2n2^n2n。 3. ZGC的流程 大致如图四个阶段，每个阶段都可以并发，两个阶段间会存在短暂停顿小阶段(Pause)，短暂停顿只与GC Roots相关，与堆内存无关。 ZGC采用并发整理算法，ZGC在标记、转移、和重定位阶段几乎是并发。 并发标记(Concurrent Mark)：前后要经历Pause Mark Start与Pause Mark End短暂停顿。ZGC的标记是指针上而不是对象上，标记阶段会更新染色指针中的Marked 0、Marked 1标志。 并发预备重分配(Concurrent Prepare for Relocate)：根据查询条件统计清理哪些Region，将这些Region组成重分配集(Relocation Set)。并非为了收益优先GC，而只是决定里面的存活对象会被重新复制到其他Region中。 并发重分配(Concurrent Relocate)：核心阶段，把重分配集中的对象复制到新的Region上，为重分配集中的每个Region维护一个转发表。 ZGC的指针&quot;自愈&quot;(如果用户线程访问了重分配集的对象，这次访问会被预置的内存屏障所截获，并根据Region的转发表记录访问到新复制的对象，同时修正更新的引用值，指向新对象)。好处只有第一次会转发，慢一次。 并发重映射(Concurrent Remap)：修正整个堆中指向重分配集中旧对象的所有引用，因为有&quot;自愈&quot;，ZGC的该阶段并不迫切，主要目的是为了不变慢。ZGC把并发重映射阶段的工作合并到下次垃圾收集的并发标记阶段处理。 4. ZGC关键技术 ZGC通过着色指针和读屏障技术，解决转移过程中的对象问题，实现并发整理。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。JVM利用对象引用的地址判断对象被移动过，即着色指针。 4.1 着色指针： 将信息存储在指针中的技术 直接将少量的额外信息存储在指针上(Linux下64位指针高18位不能用来寻址，剩下的的46位指针取其高4位存储4个标志信息，可以直接从指针上看到引用对象的三色标记、是否进入重分配集(移动过)、是否只能通过finalize()方法才能访问)。 ZGC只支持64位系统，把64位虚拟地址空间划分多个子空间： 其中，[0~4TB) 对应Java堆，[4TB ~ 8TB) 称为M0地址空间，[8TB ~ 12TB) 称为M1地址空间，[12TB ~ 16TB) 预留未使用，[16TB ~ 20TB) 称为Remapped空间。 当对象创建时，首先在堆中申请一个虚拟地址，不会真的映射物理地址，ZGC同时会在M0、M1和Remapped空间分别申请一个虚拟地址，且三个虚拟地址对应一个物理地址。但同一时刻只有一个空间有效。因为为了用&quot;空间换时间&quot;，降低GC停顿时间。 ZGC实际只使用64位地址空间的0~41位，42~45存储元数据，47~63位固定为0。ZGC将对象存活信息存储在42~45位，与传统德垃圾回收将对象存活信息放在对象头中不同。 4.2 读屏障 读屏障是JVM向应用代码插入一小段代码的技术。当应用线程从堆中读取对象引用时，就会执行这段代码。需要注意的是，仅“从堆中读取对象引用”才会触发这段代码。 读屏障示例： ZGC的读屏障代码作用：对象标记与转移过程中，用于确定对象的引用地址是否满足条件，做出相应动作。 4.3 ZGC并发地址实体切换 初始化：ZGC初始化之后，整个内存空间的地址视图被设置为Remapped。程序正常运行，在内存中分配对象，满足一定条件后垃圾回收启动，此时进入标记阶段。 并发标记阶段：第一次进入标记阶段时视图为M0，如果对象被GC标记线程或者应用线程访问过，那么就将对象的地址视图从Remapped调整为M0。所以，在标记阶段结束之后，对象的地址要么是M0视图，要么是Remapped。如果对象的地址是M0视图，那么说明对象是活跃的；如果对象的地址是Remapped视图，说明对象是不活跃的。 并发转移(重分配)阶段：标记结束后就进入转移阶段，此时地址视图再次被设置为Remapped。如果对象被GC转移线程或者应用线程访问过，那么就将对象的地址视图从M0调整为Remapped。 其实，在标记阶段存在两个地址视图M0和M1，上面的过程显示只用了一个地址视图。之所以设计成两个，是为了区别前一次标记和当前标记。也即，第二次进入并发标记阶段后，地址视图调整为M1，而非M0。 着色指针和读屏障技术不仅应用在并发转移阶段，还应用在并发标记阶段：将对象设置为已标记，传统的垃圾回收器需要进行一次内存访问，并将对象存活信息放在对象头中；而在ZGC中，只需要设置指针地址的第42~45位即可，并且因为是寄存器访问，所以速度比访问内存更快。 5. 三大优势： 某个Region的存活对象被移走后，Region能够立即被释放和重用。(能够&quot;自愈&quot;)。 大幅减少垃圾收集中的内存屏障使用量，只使用了读屏障，没使用写屏障(染色指针+不支持分代收集)。 可扩展的存储结构，Linux下64位指针还有18位没有使用。 6. 问题与解决方案： 虚拟机重新定义内存中的某几位指针，处理器只会将整个指针都视为内存地址。但x86-64不支持类似SPARC硬件的虚拟地址掩码。因此ZGC采用了虚拟内存映射技术。 Linux/x86-64平台的ZGC使用多重映射将多个不同的虚拟内存地址映射到同一个物理内存地址上，多对一意味着虚拟内存中看到的地址空间比实际的堆内存容量更大。 7. ZGC调优 请参考： 新一代垃圾回收器ZGC的探索与实践 以下参数来自上面链接的文章， 6. 垃圾收集器的选择 如果是数据分析、科学计算，目标是尽快算出结果，则应该关注吞吐量。 如果是SLA应用(网络服务提供)，停顿时间影响服务质量，延迟是关注点。 客户端应用或者嵌入式应用，应该关注垃圾收集器的占用内存。 在此基础上应该考虑JDK的发行商、JDK版本。 例如：面向用户提供服务或者软件解决方案 如果有充足的预算，没有调优经验：可以考虑商业的Zing VM。 使用较新的硬件与JDK，可以考虑ZGC。 如果是遗留系统，根据内存规模衡量：4GB~6GB堆内存，推荐CMS，对于更大的堆，可以考虑G1。 参考 《深入理解java虚拟机 JVM高级特性与最佳实践》第二部分第三章 新一代垃圾回收器ZGC的探索与实践 "},{"title":"Java内存区域","date":"2021-02-22T07:45:24.000Z","url":"/2021/02/22/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/","tags":[["Jvm","/tags/Jvm/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["java","/categories/%E5%90%8E%E7%AB%AF/java/"]],"content":"Java的内存区域在jdk1.6时发生了变化，这里主要介绍jdk1.8的内存区域，同时会指明发生了那些变化。(读书笔记) 一、运行时的数据区域 1. 内存区域划分图示 1.1 JDK1.7之前： 1.2 JDK1.8 如上图所示： 线程私有：虚拟机栈、本地方法栈、程序计数器 线程共享：堆、元空间(方法区)、直接内存(非运行时数据区的一部分) 2.虚拟机栈 虚拟机栈可以简单的理解为执行Java 方法 (也就是字节码) 服务。描述的是 Java 方法执行的内存模型。 Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 （实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。） Java虚拟机会出现两种错误：StackOverFlowerError与OutOfMemoryError(OOM)。 StackOverFlowerError：栈内存溢出错误：若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError：堆内存溢出错误：若 Java 虚拟机堆中没有空闲内存，并且垃圾回收器也无法提供更多内存的话。就会抛出 OutOfMemoryError 错误。 Java 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。 Java 方法有两种返回方式：1. return 语句。2. 抛出异常。以上两种方式会导致栈帧弹栈。 3.本地方法栈 本地方法栈可以简单的理解为执行本地 方法 (也就是Native) 服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法栈的执行也会创建栈帧。 本地方法栈也会有StackOverFlowerError与OutOfMemory错误。 4.程序计数器 程序计数器可以看作是当前线程所执行的字节码的行号指示器，字节码解释器通过改变这个计数器的值来选取下一条执行的字节码指令，分支、循环、跳转、异常处理、线程恢复(可以保存线程的执行现场) 等功能都需要依赖这个计数器来完成。 程序计数器是线程私有的，每个线程拥有自己的计数器，各计数器互不影响，目的是为了线程切换后能恢复到正确的执行位置。 程序计数器是唯一不会出现OutOfMemory错误，生命周期与自己的线程相同 5.堆 堆是JVM中最大的地方，几乎所有的对象实例都在这里分配内存 Java的垃圾回收主要在堆中，因此也被称为GC堆，Java8采用的分代垃圾回收算法 JVM垃圾回收。 堆内存分为： 新生代(Young Generation) :包括Eden区(复制算法，gc后存活的复制进入survivor或老生代(大对象))，Survivor From与Survivor To(复制) 老生代(Old Generation): (标记整理) 永生代(Permanent Generation) || 元空间(JDK1.8) 6.方法区(元空间) 线程共享，用于存放被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 方法区与永久代的关系： 永久代是HotSpot虚拟机中对方法区的一种实现。 JDK1.8移除永久代替换为元空间的原因 永久代存在OOM问题：永久代有JVM设置的固定大小，元空间受本机内存的限制，元空间OOM的几率会更小。 在 JDK8，合并 HotSpot 和 JRockit 的代码时, JRockit 从来没有一个叫永久代的东西, 合并之后就没有必要额外的设置这么一个永久代的地方了 7. 运行时常量池 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用） jdk1.7之前，运行时常量池包括字符串常量池在方法区，HotSpot的实现为永久代。 jdk1.7，字符串常量池从方法区移入堆中，运行时常量池依旧在方法区，HotSpot的实现为永久代。 jdk1.8，永久代移除，替换为元空间，运行时常量池也移入元空间。 8. 直接内存 直接内存不受java堆分配的限制，受本机总内存大小以及处理器寻址空间的限制。使用过多，依旧会出现OOM问题。 二、HotSpot虚拟机的对象管理 2.1、 对象的创建 类加载检测 当虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 类加载机制：。。。 分配内存 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 指针碰撞：堆内存规整，用过的内存一边，没用过的另一半，中间一个分界指针，只需要向没用过的内存方向移动指针即可 空闲列表：对内存不规整，堆内存维护一个列表，列表记录那块内存可用，分配的时候找一个足够大的内存来划分对象实例。 分配内存的线程安全问题： CAS+失败重试机制：虚拟机采用CAS再配上失败重试机制保证更新操作的原子性 TLAB：为每一个线程预先再EDEN区分配一块内存，JVM再给对象分配内存时首先在TLAB分配，当对象大于TLAB的剩余内存或TLAB的内存用尽时，再采用上述的CAS进行内存分配。 初始化零值 分配内存完毕之后，需要将分配的内存空间初始化为零值，保证对象实例字段不赋值也可以直接使用，能访问这些字段的数据类型对应的零值。 设置对象头 初始化零值之后，对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头 执行init方法 对虚拟机而言，对象已经产生，但java程序而言，对象创建才刚开始，对象需要执行init方法，该方法把对象（实例变量）按照程序中定义的初始赋值进行初始化； 2.2、 对象的内存布局 ​ 在HotSpot虚拟机中，对象在内存中可以分为三块区域：对象头、实例数据、对齐填充 对象头：包括两部分信息，第一部分存储对象的自身运行时数据(哈希码、GC分代年龄、锁状态的标志等等)，另一部分是类型指针，即对象指向它的类元数据的指针。 实例数据：存储有效信息，即存储程序所定义的各种类型的字段内容。 对齐填充：不必然存在，仅仅起一个占位的作用：由于HotSpot虚拟机要求对象起始地址必须是8字节的整数倍(对象的大小必须是8字节的整数倍)。填充数据不是必须存在的，仅仅是为了字节对齐。 根据“计算机组成原理”，8个字节是计算机读取和存储的最佳实践 3.3 、对象的访问定位 ​ 对象的访问由虚拟机决定，主流的有两种：1. 使用句柄、2.直接指针 句柄访问： java会将堆划分出来一部分内存去作为句柄池，reference中存储的就是对象的句柄地址，句柄中则是包含的对象实例的数据的地址和对象类型数据(如对象的类型，实现的接口、方法、父类、field等)的具体地址信息。 例：Object obj = new Object(); Object obj 表示一个本地引用，存储在java栈的本地变量表中，表示一个reference类型的数据。 new Object()作为实例对象存放在java堆中，同时java堆中还存储了Object类的信息(对象的类型、实现接口、方法等)的具体地址信息，这些地址信息所执行的数据类型存储在方法区 直接指针访问： 使用直接指针访问，java对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference中存储的直接就是对象地址，如果是访问对象本身的话，就不需要多一次间接访问的开销。 优劣势： 句柄：最大的好处是reference中存储的是稳定的句柄地址，在对象被移动(如垃圾回收的移动)时，只会改变句柄中的实例数据指针，而reference本身不需要被修改。 指针：最大的好处是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多也是一项即位可观的执行成本。 参考 《深入理解java虚拟机 JVM高级特性与最佳实践》第二部分第二章 "},{"title":"Mysql命令总结(二)","date":"2021-02-18T10:54:31.000Z","url":"/2021/02/18/Mysql%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%BA%8C)/","tags":[["Mysql","/tags/Mysql/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["sql","/categories/%E5%90%8E%E7%AB%AF/sql/"]],"content":"版权声明：本文转载自一千行 MySQL 学习笔记，并在一定程度上进行了增删改。 mysql接上篇 注：所有操作基于day01数据库 注：所有sql命令中的 [字段] 意为可选字段 十一、备份与还原 注意：以下所有命令不能在mysql的命令环境中执行，在纯命令行中执行。以下路径为windows路径 十二、视图 十三、事务 十四、锁表 参考视频：行锁、表锁、间隙锁 十五、触发器(尽量少用) 少用原因：1.sql语句部分程度上不可追踪。2.团队开发容易忽视。3.存在性能问题 参考视频：MySQL触发器设置 十六、SQL编程 十七、存储过程 参考视频：MySQL数据库存储过程 十八、用户与权限管理 十九、表维护 二十、杂项 "},{"title":"Mysql命令总结(一)","date":"2021-02-14T11:57:43.000Z","url":"/2021/02/14/Mysql%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%80)/","tags":[["Mysql","/tags/Mysql/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["sql","/categories/%E5%90%8E%E7%AB%AF/sql/"]],"content":"版权声明：本文转载自一千行 MySQL 学习笔记，并在一定程度上进行了增删改。 mysql 注：所有操作基于day01数据库 注：所有sql命令中的 [字段] 意为可选字段 创建表(以下表均为虚构)： user表： t_user表： t_money表： 一、基本操作 二、数据库的操作 三、表操作 记忆：操作表，(不操作表的数据)，都需要加上table参数 四、数据操作 注意：删改操作一定要加条件，否则就是删改整张表(准备跑路) 六、SELECT select：创建一张临时的表，来存储查询到的数据 七、UNION(注意与join区别) 八、子查询 九、连接查询(join) 十、TRUNCATE "},{"title":"三条sql语句记录","date":"2021-01-28T10:13:01.000Z","url":"/2021/01/28/%E4%B8%89%E6%9D%A1sql%E8%AF%AD%E5%8F%A5%E8%AE%B0%E5%BD%95/","tags":[["Mysql","/tags/Mysql/"]],"categories":[["后端","/categories/%E5%90%8E%E7%AB%AF/"],["sql","/categories/%E5%90%8E%E7%AB%AF/sql/"]],"content":"几条sql语句，觉得算是很常用的，遂记录下来 所用到的表的示例大致如下(数据纯属虚构) 一、统计每个月的总会员数量 这个需要在controller与业务层进行一定的逻辑，sql层只需要查询每个月的x年x月31日之前的数据即可。具体实现逻辑如下，假设查询的是近一年的每个月的会员数量： 在controller层通过日历对象遍历出近一年的数据放入集合中，格式为yyyy-MM; 在service层遍历，并手动拼接-31日，查询该年月日之前的会员总数，在存入集合 Mysql查询某个日期之前的总人数： 二、查询男女性别数量 这个只需要在sql使用即可 查询结果 三、查询会员年龄段人数 展示0-18岁，18-30岁，30-45岁，45岁以上的人数和占比。 由于数据库的日期是date类型的，所以between是包括右边界的，18要归纳到18-30岁，所以这里0-18岁只能between 0 and 17；后面的同理。 注：如果是datetime类型，是不过包括右边界的，所以可以用0 between 18； 查询结果 "},{"title":"MyBlog","date":"2021-01-19T01:10:32.000Z","url":"/2021/01/19/MyBlog/","categories":[["undefined",""]],"content":"SunFlowers"},{"title":"ElementUI+Vue+PageHelp实现分页展示","date":"2021-01-08T04:59:47.000Z","url":"/2021/01/08/ElementUI-Vue-PageHelp%E5%AE%9E%E7%8E%B0%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/","tags":[["Vue","/tags/Vue/"],["ajax","/tags/ajax/"],["ElementUI","/tags/ElementUI/"]],"categories":[["前端","/categories/%E5%89%8D%E7%AB%AF/"],["Vue","/categories/%E5%89%8D%E7%AB%AF/Vue/"]],"content":"表格的分页展示不仅能让页面更清晰，还能够减轻数据库的负担。 一、前端 前端主要实现两个功能(表格与分页使用elementUI)： 用户进入时，查询所有 用户手动查询，查询出结果，并将用户跳转到第一页的结果 1.查询所有 用户进入该页面就查询所有：则该方法必须在页面的 created() 函数中调用，同时查询语句queryString默认为null、当前页默认为1，使用findPage()方法 请求的数据全部封装在 pagination 中。 返回的所有查到的结果使用 dataList 数组接收，datalist 绑定了表格中的数据 用户切换当前页：调用 handleCurrentChange(currentPage) 方法 (注：currentPage：elementUI获取用户选择页码)，赋值当前页后，再次分页查询findPage() 2. 用户查询 用户输入绑定 queryString，则这次查询带条件， 用户查询后必须将用户定位到第一页(无论他现在在第几页)， 调用handleCurrentChange(1)，即可 3.实现 重点看几处注释处和vue的js部分即可， 二、后端 0.结果封装类 前端分页请求查询数据的封装：QueryPageBean 后端查询到的分页结果的封装：PageResult&lt;&gt; 返回的结果封装：Result 1. controller层 由于发的是post请求，所以，请求的数据需要从请求体中获取。实现如下 2. serviceImpl实现类层：(service层略) 需要判断是否有查询条件，如果有使用模糊查询。如果没有，查询全部 3.dao对应的xml(dao层略) 三、结果展示 进入页面查询全部 用户手动查询 "},{"title":"Vue发送ajax请求","date":"2021-01-06T01:33:40.000Z","url":"/2021/01/06/Vue%E5%8F%91%E9%80%81ajax%E8%AF%B7%E6%B1%82/","tags":[["Vue","/tags/Vue/"],["ajax","/tags/ajax/"],["ElementUI","/tags/ElementUI/"]],"categories":[["前端","/categories/%E5%89%8D%E7%AB%AF/"],["Vue","/categories/%E5%89%8D%E7%AB%AF/Vue/"]],"content":"Vue发送异步ajax的请求，可以使用axios来实现 ElementUI与Vue显示表格 这里的表格摘自element官网，如下内容是直接写死在表格中的，未使用任何请求。 效果 axios异步请求 Vue发送异步ajax的请求，这里可以使用axios来实现，如下是一个简单的使用的实例。 "},{"title":"Hello World","date":"2020-12-31T07:26:00.000Z","url":"/2020/12/31/hello-world/","categories":[["undefined",""]],"content":"你好世界"}]